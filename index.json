[{"categories":null,"content":"Create A Library under Your Own Control No one can interfere with your library. With Github’s popular and easy-to-use platform, you can catalog and organize all your books in one cyberspace with completely zero maintenance fee. Now, You can translate any book to your language, listen to your fond books anytime, and search content a breeze free. If you got any questions, please: ","date":"2022-09-04","objectID":"/about/:0:1","tags":null,"title":"Contact Libmind","uri":"/about/"},{"categories":null,"content":"Contact us Support website: libmind.com Mixin messenger: 29273 Mixin robot: 7000104144 Twitter: ChrisHowardaka Email: chrishowardaka@gmail.com ","date":"2022-09-04","objectID":"/about/:0:2","tags":null,"title":"Contact Libmind","uri":"/about/"},{"categories":["think"],"content":"Think Again ALSO BY ADAM GRANT Give and Take Originals Option B VIKING An imprint of Penguin Random House LLC penguinrandomhouse.com Copyright © 2021 by Adam Grant Penguin supports copyright. Copyright fuels creativity, encourages diverse voices, promotes free speech, and creates a vibrant culture. Thank you for buying an authorized edition of this book and for complying with copyright laws by not reproducing, scanning, or distributing any part of it in any form without permission. You are supporting writers and allowing Penguin to continue to publish books for every reader. Owing to limitations of space, image credits can be found on this page . Unless otherwise noted, charts illustrated by Matt Shirley. library of congress cataloging-in-publication data Names: Grant, Adam M., author. Title: Think again : the power of knowing what you don’t know / Adam Grant. Description: [New York, New York] : Viking, [2021] | Includes bibliographical references and index. Identifiers: LCCN 2020035237 (print) | LCCN 2020035238 (ebook) | ISBN 9781984878106 (hardcover) | ISBN 9781984878113 (ebook) | ISBN 9780593298749 (international edition) Subjects: LCSH: Thought and thinking. | Questioning. | Knowledge, Theory of. | Belief and doubt. Classification: LCC BF441 .G693 2021 (print) | LCC BF441 (ebook) | DDC 153.4/2—dc23 LC record available at https://lccn.loc.gov/2020035237 LC ebook record available at https://lccn.loc.gov/2020035238 Book design by Daniel Lagin While the author has made every effort to provide accurate telephone numbers, internet addresses, and other contact information at the time of publication, neither the publisher nor the author assumes any responsibility for errors or for changes that occur after publication. Further, the publisher does not have any control over and does not assume any responsibility for author or third-party websites or their content. pid_prh_5.6.1_c0_r0 To Kaan, Jeremy, and Bill, My three oldest friends—one thing I won’t rethink CONTENTS Prologue PART I. Individual Rethinking Updating Our Own Views 1. A Preacher, a Prosecutor, a Politician, and a Scientist Walk into Your Mind 2. The Armchair Quarterback and the Impostor: Finding the Sweet Spot of Confidence 3. The Joy of Being Wrong: The Thrill of Not Believing Everything You Think 4. The Good Fight Club: The Psychology of Constructive Conflict PART II. Interpersonal Rethinking Opening Other People’s Minds 5. Dances with Foes: How to Win Debates and Influence People 6. Bad Blood on the Diamond: Diminishing Prejudice by Destabilizing Stereotypes 7. Vaccine Whisperers and Mild-Mannered Interrogators: How the Right Kind of Listening Motivates People to Change PART III. Collective Rethinking Creating Communities of Lifelong Learners 8. Charged Conversations: Depolarizing Our Divided Discussions 9. Rewriting the Textbook: Teaching Students to Question Knowledge 10. That’s Not the Way We’ve Always Done It: Building Cultures of Learning at Work PART IV. Conclusion 11. Escaping Tunnel Vision: Reconsidering Our Best-Laid Career and Life Plans Epilogue Actions for Impact Acknowledgments Notes Illustration Credits Index Prologue After a bumpy flight, fifteen men dropped from the Montana sky. They weren’t skydivers. They were smokejumpers: elite wildland firefighters parachuting in to extinguish a forest fire started by lightning the day before. In a matter of minutes, they would be racing for their lives. The smokejumpers landed near the top of Mann Gulch late on a scorching August afternoon in 1949. With the fire visible across the gulch, they made their way down the slope toward the Missouri River. Their plan was to dig a line in the soil around the fire to contain it and direct it toward an area where there wasn’t much to burn. After hiking about a quarter mile, the foreman, Wagner Dodge, saw that the fire had leapt across the gulch and was heading straight at them. The flames stretched as high as 30 feet in the air. Soon the fire would be blazing fast enough t","date":"2022-09-03","objectID":"/think_again/:0:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 1 ","date":"2022-09-03","objectID":"/think_again/:1:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"A Preacher, a Prosecutor, a Politician, and a Scientist Walk into Your Mind Progress is impossible without change; and those who cannot change their minds cannot change anything. —george bernard shaw You probably don’t recognize his name, but Mike Lazaridis has had a defining impact on your life. From an early age, it was clear that Mike was something of an electronics wizard. By the time he turned four, he was building his own record player out of Legos and rubber bands. In high school, when his teachers had broken TVs, they called Mike to fix them. In his spare time, he built a computer and designed a better buzzer for high school quiz-bowl teams, which ended up paying for his first year of college. Just months before finishing his electrical engineering degree, Mike did what so many great entrepreneurs of his era would do: he dropped out of college. It was time for this son of immigrants to make his mark on the world. Mike’s first success came when he patented a device for reading the bar codes on movie film, which was so useful in Hollywood that it won an Emmy and an Oscar for technical achievement. That was small potatoes compared to his next big invention, which made his firm the fastest-growing company on the planet. Mike’s flagship device quickly attracted a cult following, with loyal customers ranging from Bill Gates to Christina Aguilera. “It’s literally changed my life,” Oprah Winfrey gushed. “I cannot live without this.” When he arrived at the White House, President Obama refused to relinquish his to the Secret Service. Mike Lazaridis dreamed up the idea for the BlackBerry as a wireless communication device for sending and receiving emails. As of the summer of 2009, it accounted for nearly half of the U.S. smartphone market. By 2014, its market share had plummeted to less than 1 percent. When a company takes a nosedive like that, we can never pinpoint a single cause of its downfall, so we tend to anthropomorphize it: BlackBerry failed to adapt. Yet adapting to a changing environment isn’t something a company does—it’s something people do in the multitude of decisions they make every day. As the cofounder, president, and co-CEO, Mike was in charge of all the technical and product decisions on the BlackBerry. Although his thinking may have been the spark that ignited the smartphone revolution, his struggles with rethinking ended up sucking the oxygen out of his company and virtually extinguishing his invention. Where did he go wrong? Most of us take pride in our knowledge and expertise, and in staying true to our beliefs and opinions. That makes sense in a stable world, where we get rewarded for having conviction in our ideas. The problem is that we live in a rapidly changing world, where we need to spend as much time rethinking as we do thinking. Rethinking is a skill set, but it’s also a mindset. We already have many of the mental tools we need. We just have to remember to get them out of the shed and remove the rust. ","date":"2022-09-03","objectID":"/think_again/:2:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"SECOND THOUGHTS With advances in access to information and technology, knowledge isn’t just increasing. It’s increasing at an increasing rate. In 2011, you consumed about five times as much information per day as you would have just a quarter century earlier. As of 1950, it took about fifty years for knowledge in medicine to double. By 1980, medical knowledge was doubling every seven years, and by 2010, it was doubling in half that time. The accelerating pace of change means that we need to question our beliefs more readily than ever before. This is not an easy task. As we sit with our beliefs, they tend to become more extreme and more entrenched. I’m still struggling to accept that Pluto may not be a planet. In education, after revelations in history and revolutions in science, it often takes years for a curriculum to be updated and textbooks to be revised. Researchers have recently discovered that we need to rethink widely accepted assumptions about such subjects as Cleopatra’s roots (her father was Greek, not Egyptian, and her mother’s identity is unknown); the appearance of dinosaurs (paleontologists now think some tyrannosaurs had colorful feathers on their backs); and what’s required for sight (blind people have actually trained themselves to “see”—sound waves can activate the visual cortex and create representations in the mind’s eye, much like how echolocation helps bats navigate in the dark).* Vintage records, classic cars, and antique clocks might be valuable collectibles, but outdated facts are mental fossils that are best abandoned. We’re swift to recognize when other people need to think again. We question the judgment of experts whenever we seek out a second opinion on a medical diagnosis. Unfortunately, when it comes to our own knowledge and opinions, we often favor feeling right over being right. In everyday life, we make many diagnoses of our own, ranging from whom we hire to whom we marry. We need to develop the habit of forming our own second opinions. Imagine you have a family friend who’s a financial adviser, and he recommends investing in a retirement fund that isn’t in your employer’s plan. You have another friend who’s fairly knowledgeable about investing, and he tells you that this fund is risky. What would you do? When a man named Stephen Greenspan found himself in that situation, he decided to weigh his skeptical friend’s warning against the data available. His sister had been investing in the fund for several years, and she was pleased with the results. A number of her friends had been, too; although the returns weren’t extraordinary, they were consistently in the double digits. The financial adviser was enough of a believer that he had invested his own money in the fund. Armed with that information, Greenspan decided to go forward. He made a bold move, investing nearly a third of his retirement savings in the fund. Before long, he learned that his portfolio had grown by 25 percent. Then he lost it all overnight when the fund collapsed. It was the Ponzi scheme managed by Bernie Madoff. Two decades ago my colleague Phil Tetlock discovered something peculiar. As we think and talk, we often slip into the mindsets of three different professions: preachers, prosecutors, and politicians. In each of these modes, we take on a particular identity and use a distinct set of tools. We go into preacher mode when our sacred beliefs are in jeopardy: we deliver sermons to protect and promote our ideals. We enter prosecutor mode when we recognize flaws in other people’s reasoning: we marshal arguments to prove them wrong and win our case. We shift into politician mode when we’re seeking to win over an audience: we campaign and lobby for the approval of our constituents. The risk is that we become so wrapped up in preaching that we’re right, prosecuting others who are wrong, and politicking for support that we don’t bother to rethink our own views. When Stephen Greenspan and his sister made the choice to invest with ","date":"2022-09-03","objectID":"/think_again/:2:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"A DIFFERENT PAIR OF GOGGLES If you’re a scientist by trade, rethinking is fundamental to your profession. You’re paid to be constantly aware of the limits of your understanding. You’re expected to doubt what you know, be curious about what you don’t know, and update your views based on new data. In the past century alone, the application of scientific principles has led to dramatic progress. Biological scientists discovered penicillin. Rocket scientists sent us to the moon. Computer scientists built the internet. But being a scientist is not just a profession. It’s a frame of mind—a mode of thinking that differs from preaching, prosecuting, and politicking. We move into scientist mode when we’re searching for the truth: we run experiments to test hypotheses and discover knowledge. Scientific tools aren’t reserved for people with white coats and beakers, and using them doesn’t require toiling away for years with a microscope and a petri dish. Hypotheses have as much of a place in our lives as they do in the lab. Experiments can inform our daily decisions. That makes me wonder: is it possible to train people in other fields to think more like scientists, and if so, do they end up making smarter choices? Recently, a quartet of European researchers decided to find out. They ran a bold experiment with more than a hundred founders of Italian startups in technology, retail, furniture, food, health care, leisure, and machinery. Most of the founders’ businesses had yet to bring in any revenue, making it an ideal setting to investigate how teaching scientific thinking would influence the bottom line. The entrepreneurs arrived in Milan for a training program in entrepreneurship. Over the course of four months, they learned to create a business strategy, interview customers, build a minimum viable product, and then refine a prototype. What they didn’t know was that they’d been randomly assigned to either a “scientific thinking” group or a control group. The training for both groups was identical, except that one was encouraged to view startups through a scientist’s goggles. From that perspective, their strategy is a theory, customer interviews help to develop hypotheses, and their minimum viable product and prototype are experiments to test those hypotheses. Their task is to rigorously measure the results and make decisions based on whether their hypotheses are supported or refuted. Over the following year, the startups in the control group averaged under $300 in revenue. The startups in the scientific thinking group averaged over $12,000 in revenue. They brought in revenue more than twice as fast—and attracted customers sooner, too. Why? The entrepreneurs in the control group tended to stay wedded to their original strategies and products. It was too easy to preach the virtues of their past decisions, prosecute the vices of alternative options, and politick by catering to advisers who favored the existing direction. The entrepreneurs who had been taught to think like scientists, in contrast, pivoted more than twice as often. When their hypotheses weren’t supported, they knew it was time to rethink their business models. What’s surprising about these results is that we typically celebrate great entrepreneurs and leaders for being strong-minded and clear-sighted. They’re supposed to be paragons of conviction: decisive and certain. Yet evidence reveals that when business executives compete in tournaments to price products, the best strategists are actually slow and unsure. Like careful scientists, they take their time so they have the flexibility to change their minds. I’m beginning to think decisiveness is overrated . . . but I reserve the right to change my mind. Just as you don’t have to be a professional scientist to reason like one, being a professional scientist doesn’t guarantee that someone will use the tools of their training. Scientists morph into preachers when they present their pet theories as gospel and treat thoughtful critiq","date":"2022-09-03","objectID":"/think_again/:2:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE SMARTER THEY ARE, THE HARDER THEY FAIL Mental horsepower doesn’t guarantee mental dexterity. No matter how much brainpower you have, if you lack the motivation to change your mind, you’ll miss many occasions to think again. Research reveals that the higher you score on an IQ test, the more likely you are to fall for stereotypes, because you’re faster at recognizing patterns. And recent experiments suggest that the smarter you are, the more you might struggle to update your beliefs. One study investigated whether being a math whiz makes you better at analyzing data. The answer is yes—if you’re told the data are about something bland, like a treatment for skin rashes. But what if the exact same data are labeled as focusing on an ideological issue that activates strong emotions—like gun laws in the United States? Being a quant jock makes you more accurate in interpreting the results—as long as they support your beliefs. Yet if the empirical pattern clashes with your ideology, math prowess is no longer an asset; it actually becomes a liability. The better you are at crunching numbers, the more spectacularly you fail at analyzing patterns that contradict your views. If they were liberals, math geniuses did worse than their peers at evaluating evidence that gun bans failed. If they were conservatives, they did worse at assessing evidence that gun bans worked. In psychology there are at least two biases that drive this pattern. One is confirmation bias: seeing what we expect to see. The other is desirability bias: seeing what we want to see. These biases don’t just prevent us from applying our intelligence. They can actually contort our intelligence into a weapon against the truth. We find reasons to preach our faith more deeply, prosecute our case more passionately, and ride the tidal wave of our political party. The tragedy is that we’re usually unaware of the resulting flaws in our thinking. My favorite bias is the “I’m not biased” bias, in which people believe they’re more objective than others. It turns out that smart people are more likely to fall into this trap. The brighter you are, the harder it can be to see your own limitations. Being good at thinking can make you worse at rethinking. When we’re in scientist mode, we refuse to let our ideas become ideologies. We don’t start with answers or solutions; we lead with questions and puzzles. We don’t preach from intuition; we teach from evidence. We don’t just have healthy skepticism about other people’s arguments; we dare to disagree with our own arguments. Thinking like a scientist involves more than just reacting with an open mind. It means being actively open-minded. It requires searching for reasons why we might be wrong—not for reasons why we must be right—and revising our views based on what we learn. That rarely happens in the other mental modes. In preacher mode, changing our minds is a mark of moral weakness; in scientist mode, it’s a sign of intellectual integrity. In prosecutor mode, allowing ourselves to be persuaded is admitting defeat; in scientist mode, it’s a step toward the truth. In politician mode, we flip-flop in response to carrots and sticks; in scientist mode, we shift in the face of sharper logic and stronger data. I’ve done my best to write this book in scientist mode.* I’m a teacher, not a preacher. I can’t stand politics, and I hope a decade as a tenured professor has cured me of whatever temptation I once felt to appease my audience. Although I’ve spent more than my share of time in prosecutor mode, I’ve decided that in a courtroom I’d rather be the judge. I don’t expect you to agree with everything I think. My hope is that you’ll be intrigued by how I think—and that the studies, stories, and ideas covered here will lead you to do some rethinking of your own. After all, the purpose of learning isn’t to affirm our beliefs; it’s to evolve our beliefs. One of my beliefs is that we shouldn’t be open-minded in every circumstance. There are situations ","date":"2022-09-03","objectID":"/think_again/:2:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"DON’T STOP UNBELIEVING As I’ve studied the process of rethinking, I’ve found that it often unfolds in a cycle. It starts with intellectual humility—knowing what we don’t know. We should all be able to make a long list of areas where we’re ignorant. Mine include art, financial markets, fashion, chemistry, food, why British accents turn American in songs, and why it’s impossible to tickle yourself. Recognizing our shortcomings opens the door to doubt. As we question our current understanding, we become curious about what information we’re missing. That search leads us to new discoveries, which in turn maintain our humility by reinforcing how much we still have to learn. If knowledge is power, knowing what we don’t know is wisdom. Scientific thinking favors humility over pride, doubt over certainty, curiosity over closure. When we shift out of scientist mode, the rethinking cycle breaks down, giving way to an overconfidence cycle. If we’re preaching, we can’t see gaps in our knowledge: we believe we’ve already found the truth. Pride breeds conviction rather than doubt, which makes us prosecutors: we might be laser-focused on changing other people’s minds, but ours is set in stone. That launches us into confirmation bias and desirability bias. We become politicians, ignoring or dismissing whatever doesn’t win the favor of our constituents—our parents, our bosses, or the high school classmates we’re still trying to impress. We become so busy putting on a show that the truth gets relegated to a backstage seat, and the resulting validation can make us arrogant. We fall victim to the fat-cat syndrome, resting on our laurels instead of pressure-testing our beliefs. In the case of the BlackBerry, Mike Lazaridis was trapped in an overconfidence cycle. Taking pride in his successful invention gave him too much conviction. Nowhere was that clearer than in his preference for the keyboard over a touchscreen. It was a BlackBerry virtue he loved to preach—and an Apple vice he was quick to prosecute. As his company’s stock fell, Mike got caught up in confirmation bias and desirability bias, and fell victim to validation from fans. “It’s an iconic product,” he said of the BlackBerry in 2011. “It’s used by business, it’s used by leaders, it’s used by celebrities.” By 2012, the iPhone had captured a quarter of the global smartphone market, but Mike was still resisting the idea of typing on glass. “I don’t get this,” he said at a board meeting, pointing at a phone with a touchscreen. “The keyboard is one of the reasons they buy BlackBerrys.” Like a politician who campaigns only to his base, he focused on the keyboard taste of millions of existing users, neglecting the appeal of a touchscreen to billions of potential users. For the record, I still miss the keyboard, and I’m excited that it’s been licensed for an attempted comeback. When Mike finally started reimagining the screen and software, some of his engineers didn’t want to abandon their past work. The failure to rethink was widespread. In 2011, an anonymous high-level employee inside the firm wrote an open letter to Mike and his co-CEO. “We laughed and said they are trying to put a computer on a phone, that it won’t work,” the letter read. “We are now 3–4 years too late.” Our convictions can lock us in prisons of our own making. The solution is not to decelerate our thinking—it’s to accelerate our rethinking. That’s what resurrected Apple from the brink of bankruptcy to become the world’s most valuable company. The legend of Apple’s renaissance revolves around the lone genius of Steve Jobs. It was his conviction and clarity of vision, the story goes, that gave birth to the iPhone. The reality is that he was dead-set against the mobile phone category. His employees had the vision for it, and it was their ability to change his mind that really revived Apple. Although Jobs knew how to “think different,” it was his team that did much of the rethinking. In 2004, a small group of engineers, designe","date":"2022-09-03","objectID":"/think_again/:2:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 2 ","date":"2022-09-03","objectID":"/think_again/:3:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"The Armchair Quarterback and the Impostor ","date":"2022-09-03","objectID":"/think_again/:4:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Finding the Sweet Spot of Confidence Ignorance more frequently begets confidence than does knowledge. —charles darwin When Ursula Mercz was admitted to the clinic, she complained of headaches, back pain, and dizziness severe enough that she could no longer work. Over the following month her condition deteriorated. She struggled to locate the glass of water she put next to her bed. She couldn’t find the door to her room. She walked directly into her bed frame. Ursula was a seamstress in her midfifties, and she hadn’t lost her dexterity: she was able to cut different shapes out of paper with scissors. She could easily point to her nose, mouth, arms, and legs, and had no difficulty describing her home and her pets. For an Austrian doctor named Gabriel Anton, she presented a curious case. When Anton put a red ribbon and scissors on the table in front of her, she couldn’t name them, even though “she confirmed, calmly and faithfully, that she could see the presented objects.” She was clearly having problems with language production, which she acknowledged, and with spatial orientation. Yet something else was wrong: Ursula could no longer tell the difference between light and dark. When Anton held up an object and asked her to describe it, she didn’t even try to look at it but instead reached out to touch it. Tests showed that her eyesight was severely impaired. Oddly, when Anton asked her about the deficit, she insisted she could see. Eventually, when she lost her vision altogether, she remained completely unaware of it. “It was now extremely astonishing,” Anton wrote, “that the patient did not notice her massive and later complete loss of her ability to see . . . she was mentally blind to her blindness.” It was the late 1800s, and Ursula wasn’t alone. A decade earlier a neuropathologist in Zurich had reported a case of a man who suffered an accident that left him blind but was unaware of it despite being “intellectually unimpaired.” Although he didn’t blink when a fist was placed in front of his face and couldn’t see the food on his plate, “he thought he was in a dark humid hole or cellar.” Half a century later, a pair of doctors reported six cases of people who had gone blind but claimed otherwise. “One of the most striking features in the behavior of our patients was their inability to learn from their experiences,” the doctors wrote: As they were not aware of their blindness when they walked about, they bumped into the furniture and walls but did not change their behavior. When confronted with their blindness in a rather pointed fashion, they would either deny any visual difficulty or remark: “It is so dark in the room; why don’t they turn the light on?”; “I forgot my glasses,” or “My vision is not too good, but I can see all right.” The patients would not accept any demonstration or assurance which would prove their blindness. This phenomenon was first described by the Roman philosopher Seneca, who wrote of a woman who was blind but complained that she was simply in a dark room. It’s now accepted in the medical literature as Anton’s syndrome—a deficit of self-awareness in which a person is oblivious to a physical disability but otherwise doing fairly well cognitively. It’s known to be caused by damage to the occipital lobe of the brain. Yet I’ve come to believe that even when our brains are functioning normally, we’re all vulnerable to a version of Anton’s syndrome. We all have blind spots in our knowledge and opinions. The bad news is that they can leave us blind to our blindness, which gives us false confidence in our judgment and prevents us from rethinking. The good news is that with the right kind of confidence, we can learn to see ourselves more clearly and update our views. In driver’s training we were taught to identify our visual blind spots and eliminate them with the help of mirrors and sensors. In life, since our minds don’t come equipped with those tools, we need to learn to recognize our cognitive blind spots and ","date":"2022-09-03","objectID":"/think_again/:5:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"A TALE OF TWO SYNDROMES On the first day of December 2015, Halla Tómasdóttir got a call she never expected. The roof of Halla’s house had just given way to a thick layer of snow and ice. As she watched water pouring down one of the walls, the friend on the other end of the line asked if Halla had seen the Facebook posts about her. Someone had started a petition for Halla to run for the presidency of Iceland. Halla’s first thought was, Who am I to be president? She had helped start a university and then cofounded an investment firm in 2007. When the 2008 financial crisis rocked the world, Iceland was hit particularly hard; all three of its major private commercial banks defaulted and its currency collapsed. Relative to the size of its economy, the country faced the worst financial meltdown in human history, but Halla demonstrated her leadership skills by guiding her firm successfully through the crisis. Even with that accomplishment, she didn’t feel prepared for the presidency. She had no political background; she had never served in government or in any kind of public-sector role. It wasn’t the first time Halla had felt like an impostor. At the age of eight, her piano teacher had placed her on a fast track and frequently asked her to play in concerts, but she never felt she was worthy of the honor—and so, before every concert, she felt sick. Although the stakes were much higher now, the self-doubt felt familiar. “I had a massive pit in my stomach, like the piano recital but much bigger,” Halla told me. “It’s the worst case of adult impostor syndrome I’ve ever had.” For months, she struggled with the idea of becoming a candidate. As her friends and family encouraged her to recognize that she had some relevant skills, Halla was still convinced that she lacked the necessary experience and confidence. She tried to persuade other women to run—one of whom ended up ascending to a different office, as the prime minister of Iceland. Yet the petition didn’t go away, and Halla’s friends, family, and colleagues didn’t stop urging her on. Eventually, she found herself asking, Who am I not to serve? She ultimately decided to go for it, but the odds were heavily stacked against her. She was running as an unknown independent candidate in a field of more than twenty contenders. One of her competitors was particularly powerful—and particularly dangerous. When an economist was asked to name the three people most responsible for Iceland’s bankruptcy, she nominated Davíð Oddsson for all three spots. As Iceland’s prime minister from 1991 to 2004, Oddsson put the country’s banks in jeopardy by privatizing them. Then, as governor of Iceland’s central bank from 2005 to 2009, he allowed the banks’ balance sheets to balloon to more than ten times the national GDP. When the people protested his mismanagement, Oddsson refused to resign and had to be forced out by Parliament. Time magazine later identified him as one of the twenty-five people to blame for the financial crisis worldwide. Nevertheless, in 2016 Oddsson announced his candidacy for the presidency of Iceland: “My experience and knowledge, which is considerable, could go well with this office.” In theory, confidence and competence go hand in hand. In practice, they often diverge. You can see it when people rate their own leadership skills and are also evaluated by their colleagues, supervisors, or subordinates. In a meta-analysis of ninety-five studies involving over a hundred thousand people, women typically underestimated their leadership skills, while men overestimated their skills. You’ve probably met some football fans who are convinced they know more than the coaches on the sidelines. That’s the armchair quarterback syndrome, where confidence exceeds competence. Even after calling financial plays that destroyed an economy, Davíð Oddsson still refused to acknowledge that he wasn’t qualified to coach—let alone quarterback. He was blind to his weaknesses. Jason Adam Katzenstein/The New Yorker ","date":"2022-09-03","objectID":"/think_again/:5:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE IGNORANCE OF ARROGANCE One of my favorite accolades is a satirical award for research that’s as entertaining as it is enlightening. It’s called the Ig™ Nobel Prize, and it’s handed out by actual Nobel laureates. One autumn in college, I raced to the campus theater to watch the ceremony along with over a thousand fellow nerds. The winners included a pair of physicists who created a magnetic field to levitate a live frog, a trio of chemists who discovered that the biochemistry of romantic love has something in common with obsessive-compulsive disorder, and a computer scientist who invented PawSense—software that detects cat paws on a keyboard and makes an annoying noise to deter them. Unclear whether it also worked with dogs. Several of the awards made me laugh, but the honorees who made me think the most were two psychologists, David Dunning and Justin Kruger. They had just published a “modest report” on skill and confidence that would soon become famous. They found that in many situations, those who can’t . . . don’t know they can’t. According to what’s now known as the Dunning-Kruger effect, it’s when we lack competence that we’re most likely to be brimming with overconfidence. In the original Dunning-Kruger studies, people who scored the lowest on tests of logical reasoning, grammar, and sense of humor had the most inflated opinions of their skills. On average, they believed they did better than 62 percent of their peers, but in reality outperformed only 12 percent of them. The less intelligent we are in a particular domain, the more we seem to overestimate our actual intelligence in that domain. In a group of football fans, the one who knows the least is the most likely to be the armchair quarterback, prosecuting the coach for calling the wrong play and preaching about a better playbook. This tendency matters because it compromises self-awareness, and it trips us up across all kinds of settings. Look what happened when economists evaluated the operations and management practices of thousands of companies across a wide range of industries and countries, and compared their assessments with managers’ self-ratings: Sources: World Management Survey; Bloom and Van Reenen 2007; and Maloney 2017b. In this graph, if self-assessments of performance matched actual performance, every country would be on the dotted line. Overconfidence existed in every culture, and it was most rampant where management was the poorest.* Of course, management skills can be hard to judge objectively. Knowledge should be easier—you were tested on yours throughout school. Compared to most people, how much do you think you know about each of the following topics—more, less, or the same? Why English became the official language of the United States Why women were burned at the stake in Salem What job Walt Disney had before he drew Mickey Mouse On which spaceflight humans first laid eyes on the Great Wall of China Why eating candy affects how kids behave One of my biggest pet peeves is feigned knowledge, where people pretend to know things they don’t. It bothers me so much that at this very moment I’m writing an entire book about it. In a series of studies, people rated whether they knew more or less than most people about a range of topics like these, and then took a quiz to test their actual knowledge. The more superior participants thought their knowledge was, the more they overestimated themselves—and the less interested they were in learning and updating. If you think you know more about history or science than most people, chances are you know less than you think. As Dunning quips, “The first rule of the Dunning-Kruger club is you don’t know you’re a member of the Dunning-Kruger club.”* On the questions above, if you felt you knew anything at all, think again. America has no official language, suspected witches were hanged in Salem but not burned, Walt Disney didn’t draw Mickey Mouse (it was the work of an animator named Ub Iwerks), you can’t actually","date":"2022-09-03","objectID":"/think_again/:5:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"STRANDED AT THE SUMMIT OF MOUNT STUPID The problem with armchair quarterback syndrome is that it stands in the way of rethinking. If we’re certain that we know something, we have no reason to look for gaps and flaws in our knowledge—let alone fill or correct them. In one study, the people who scored the lowest on an emotional intelligence test weren’t just the most likely to overestimate their skills. They were also the most likely to dismiss their scores as inaccurate or irrelevant—and the least likely to invest in coaching or self-improvement. Yes, some of this comes down to our fragile egos. We’re driven to deny our weaknesses when we want to see ourselves in a positive light or paint a glowing picture of ourselves to others. A classic case is the crooked politician who claims to crusade against corruption, but is actually motivated by willful blindness or social deception. Yet motivation is only part of the story.* There’s a less obvious force that clouds our vision of our abilities: a deficit in metacognitive skill, the ability to think about our thinking. Lacking competence can leave us blind to our own incompetence. If you’re a tech entrepreneur and you’re uninformed about education systems, you can feel certain that your master plan will fix them. If you’re socially awkward and you’re missing some insight on social graces, you can strut around believing you’re James Bond. In high school, a friend told me I didn’t have a sense of humor. What made her think that? “You don’t laugh at all my jokes.” I’m hilarious . . . said no funny person ever. I’ll leave it to you to decide who lacked the sense of humor. When we lack the knowledge and skills to achieve excellence, we sometimes lack the knowledge and skills to judge excellence. This insight should immediately put your favorite confident ignoramuses in their place. Before we poke fun at them, though, it’s worth remembering that we all have moments when we are them. We’re all novices at many things, but we’re not always blind to that fact. We tend to overestimate ourselves on desirable skills, like the ability to carry on a riveting conversation. We’re also prone to overconfidence in situations where it’s easy to confuse experience for expertise, like driving, typing, trivia, and managing emotions. Yet we underestimate ourselves when we can easily recognize that we lack experience—like painting, driving a race car, and rapidly reciting the alphabet backward. Absolute beginners rarely fall into the Dunning-Kruger trap. If you don’t know a thing about football, you probably don’t walk around believing you know more than the coach. It’s when we progress from novice to amateur that we become overconfident. A bit of knowledge can be a dangerous thing. In too many domains of our lives, we never gain enough expertise to question our opinions or discover what we don’t know. We have just enough information to feel self-assured about making pronouncements and passing judgment, failing to realize that we’ve climbed to the top of Mount Stupid without making it over to the other side. You can see this phenomenon in one of Dunning’s experiments that involved people playing the role of doctors in a simulated zombie apocalypse. When they’ve seen only a handful of injured victims, their perceived and actual skills match. Unfortunately, as they gain experience, their confidence climbs faster than their competence, and confidence remains higher than competence from that point on. This might be one of the reasons that patient mortality rates in hospitals seem to spike in July, when new residents take over. It’s not their lack of skill alone that proves hazardous; it’s their overestimation of that skill. Advancing from novice to amateur can break the rethinking cycle. As we gain experience, we lose some of our humility. We take pride in making rapid progress, which promotes a false sense of mastery. That jump-starts an overconfidence cycle, preventing us from doubting what we know and being cur","date":"2022-09-03","objectID":"/think_again/:5:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"WHAT GOLDILOCKS GOT WRONG Many people picture confidence as a seesaw. Gain too much confidence, and we tip toward arrogance. Lose too much confidence, and we become meek. This is our fear with humility: that we’ll end up having a low opinion of ourselves. We want to keep the seesaw balanced, so we go into Goldilocks mode and look for the amount of confidence that’s just right. Recently, though, I learned that this is the wrong approach. Humility is often misunderstood. It’s not a matter of having low self-confidence. One of the Latin roots of humility means “from the earth.” It’s about being grounded—recognizing that we’re flawed and fallible. Confidence is a measure of how much you believe in yourself. Evidence shows that’s distinct from how much you believe in your methods. You can be confident in your ability to achieve a goal in the future while maintaining the humility to question whether you have the right tools in the present. That’s the sweet spot of confidence. We become blinded by arrogance when we’re utterly convinced of our strengths and our strategies. We get paralyzed by doubt when we lack conviction in both. We can be consumed by an inferiority complex when we know the right method but feel uncertain about our ability to execute it. What we want to attain is confident humility: having faith in our capability while appreciating that we may not have the right solution or even be addressing the right problem. That gives us enough doubt to reexamine our old knowledge and enough confidence to pursue new insights. When Spanx founder Sara Blakely had the idea for footless pantyhose, she believed in her ability to make the idea a reality, but she was full of doubt about her current tools. Her day job was selling fax machines door-to-door, and she was aware that she didn’t know anything about fashion, retail, or manufacturing. When she was designing the prototype, she spent a week driving around to hosiery mills to ask them for help. When she couldn’t afford a law firm to apply for a patent, she read a book on the topic and filled out the application herself. Her doubt wasn’t debilitating—she was confident she could overcome the challenges in front of her. Her confidence wasn’t in her existing knowledge—it was in her capacity to learn. Confident humility can be taught. In one experiment, when students read a short article about the benefits of admitting what we don’t know rather than being certain about it, their odds of seeking extra help in an area of weakness spiked from 65 to 85 percent. They were also more likely to explore opposing political views to try to learn from the other side. Confident humility doesn’t just open our minds to rethinking—it improves the quality of our rethinking. In college and graduate school, students who are willing to revise their beliefs get higher grades than their peers. In high school, students who admit when they don’t know something are rated by teachers as learning more effectively and by peers as contributing more to their teams. At the end of the academic year, they have significantly higher math grades than their more self-assured peers. Instead of just assuming they’ve mastered the material, they quiz themselves to test their understanding. When adults have the confidence to acknowledge what they don’t know, they pay more attention to how strong evidence is and spend more time reading material that contradicts their opinions. In rigorous studies of leadership effectiveness across the United States and China, the most productive and innovative teams aren’t run by leaders who are confident or humble. The most effective leaders score high in both confidence and humility. Although they have faith in their strengths, they’re also keenly aware of their weaknesses. They know they need to recognize and transcend their limits if they want to push the limits of greatness. If we care about accuracy, we can’t afford to have blind spots. To get an accurate picture of our knowledge and skill","date":"2022-09-03","objectID":"/think_again/:5:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE BENEFITS OF DOUBT Just a month and a half before Iceland’s presidential election, Halla Tómasdóttir was polling at only 1 percent support. To focus on the most promising candidates, the network airing the first televised debate announced that they wouldn’t feature anyone with less than 2.5 percent of the vote. On the day of the debate, Halla ended up barely squeaking through. Over the following month her popularity skyrocketed. She wasn’t just a viable candidate; she was in the final four. A few years later, when I invited her to speak to my class, Halla mentioned that the psychological fuel that propelled her meteoric rise was none other than impostor syndrome. Feeling like an impostor is typically viewed as a bad thing, and for good reason—a chronic sense of being unworthy can breed misery, crush motivation, and hold us back from pursuing our ambitions. From time to time, though, a less crippling sense of doubt waltzes into many of our minds. Some surveys suggest that more than half the people you know have felt like impostors at some point in their careers. It’s thought to be especially common among women and marginalized groups. Strangely, it also seems to be particularly pronounced among high achievers. I’ve taught students who earned patents before they could drink and became chess masters before they could drive, but these same individuals still wrestle with insecurity and constantly question their abilities. The standard explanation for their accomplishments is that they succeed in spite of their doubts, but what if their success is actually driven in part by those doubts? To find out, Basima Tewfik—then a doctoral student at Wharton, now an MIT professor—recruited a group of medical students who were preparing to begin their clinical rotations. She had them interact for more than half an hour with actors who had been trained to play the role of patients presenting symptoms of various diseases. Basima observed how the medical students treated the patients—and also tracked whether they made the right diagnoses. A week earlier the students had answered a survey about how often they entertained impostor thoughts like I am not as qualified as others think I am and People important to me think I am more capable than I think I am. Those who self-identified as impostors didn’t do any worse in their diagnoses, and they did significantly better when it came to bedside manner—they were rated as more empathetic, respectful, and professional, as well as more effective in asking questions and sharing information. In another study, Basima found a similar pattern with investment professionals: the more often they felt like impostors, the higher their performance reviews from their supervisors four months later. This evidence is new, and we still have a lot to learn about when impostor syndrome is beneficial versus when it’s detrimental. Still, it leaves me wondering if we’ve been misjudging impostor syndrome by seeing it solely as a disorder. When our impostor fears crop up, the usual advice is to ignore them—give ourselves the benefit of the doubt. Instead, we might be better off embracing those fears, because they can give us three benefits of doubt. The first upside of feeling like an impostor is that it can motivate us to work harder. It’s probably not helpful when we’re deciding whether to start a race, but once we’ve stepped up to the starting line, it gives us the drive to keep running to the end so that we can earn our place among the finalists.* In some of my own research across call centers, military and government teams, and nonprofits, I’ve found that confidence can make us complacent. If we never worry about letting other people down, we’re more likely to actually do so. When we feel like impostors, we think we have something to prove. Impostors may be the last to jump in, but they may also be the last to bail out. Second, impostor thoughts can motivate us to work smarter. When we don’t believe we’re going to win, we","date":"2022-09-03","objectID":"/think_again/:5:5","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE LEAGUE OF EXTRAORDINARY HUMILITY When I sat down with Halla, she told me that in the past her doubts had been debilitating. She took them as a sign that she lacked the ability to succeed. Now she had reached a point of confident humility, and she interpreted doubts differently: they were a cue that she needed to improve her tools. Plenty of evidence suggests that confidence is just as often the result of progress as the cause of it. We don’t have to wait for our confidence to rise to achieve challenging goals. We can build it through achieving challenging goals. “I have come to welcome impostor syndrome as a good thing: it’s fuel to do more, try more,” Halla says. “I’ve learned to use it to my advantage. I actually thrive on the growth that comes from the self-doubt.” While other candidates were content to rely on the usual media coverage, Halla’s uncertainty about her tools made her eager to rethink the way campaigns were run. She worked harder and smarter, staying up late to personally answer social media messages. She held Facebook Live sessions where voters could ask her anything, and learned to use Snapchat to reach young people. Deciding she had nothing to lose, she went where few presidential candidates had gone before: instead of prosecuting her opponents, she ran a positive campaign. How much worse can it get? she thought. It was part of why she resonated so strongly with voters: they were tired of watching candidates smear one another and delighted to see a candidate treat her competitors with respect. Uncertainty primes us to ask questions and absorb new ideas. It protects us against the Dunning-Kruger effect. “Impostor syndrome always keeps me on my toes and growing because I never think I know it all,” Halla reflects, sounding more like a scientist than a politician. “Maybe impostor syndrome is needed for change. Impostors rarely say, ‘This is how we do things around here.’ They don’t say, ‘This is the right way.’ I was so eager to learn and grow that I asked everyone for advice on how I could do things differently.” Although she doubted her tools, she had confidence in herself as a learner. She understood that knowledge is best sought from experts, but creativity and wisdom can come from anywhere. Iceland’s presidential election came down to Halla, Davíð Oddsson, and two other men. The three men all enjoyed more media coverage than Halla throughout the campaign, including front-page interviews, which she never received. They also had bigger campaign budgets. Yet on election day, Halla stunned her country—and herself—by winning more than a quarter of the vote. She didn’t land the presidency; she came in second. Her 28 percent fell shy of the victor’s 39 percent. But Halla trounced Davíð Oddsson, who finished fourth, with less than 14 percent. Based on her trajectory and momentum, it’s not crazy to imagine that with a few more weeks, she could have won. Great thinkers don’t harbor doubts because they’re impostors. They maintain doubts because they know we’re all partially blind and they’re committed to improving their sight. They don’t boast about how much they know; they marvel at how little they understand. They’re aware that each answer raises new questions, and the quest for knowledge is never finished. A mark of lifelong learners is recognizing that they can learn something from everyone they meet. Arrogance leaves us blind to our weaknesses. Humility is a reflective lens: it helps us see them clearly. Confident humility is a corrective lens: it enables us to overcome those weaknesses. ","date":"2022-09-03","objectID":"/think_again/:5:6","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 3 ","date":"2022-09-03","objectID":"/think_again/:6:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"The Joy of Being Wrong ","date":"2022-09-03","objectID":"/think_again/:7:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"The Thrill of Not Believing Everything You Think I have a degree from Harvard. Whenever I’m wrong, the world makes a little less sense. —dr. frasier crane, played by kelsey grammer In the fall of 1959, a prominent psychologist welcomed new participants into a wildly unethical study. He had handpicked a group of Harvard sophomores to join a series of experiments that would run through the rest of their time in college. The students volunteered to spend a couple of hours a week contributing to knowledge about how personality develops and how psychological problems can be solved. They had no idea that they were actually signing up to have their beliefs attacked. The researcher, Henry Murray, had originally trained as a physician and biochemist. After becoming a distinguished psychologist, he was disillusioned that his field paid little attention to how people navigate difficult interactions, so he decided to create them in his own lab. He gave students a month to write out their personal philosophy of life, including their core values and guiding principles. When they showed up to submit their work, they were paired with another student who had done the same exercise. They would have a day or two to read each other’s philosophies, and then they would be filmed debating them. The experience would be much more intense than they anticipated. Murray modeled the study on psychological assessments he had developed for spies in World War II. As a lieutenant colonel, Murray had been recruited to vet potential agents for the Office of Strategic Services, the precursor to the CIA. To gauge how candidates would handle pressure, he sent them down to a basement to be interrogated with a bright light shining in their faces. The examiner would wait for an inconsistency in their accounts to pop up and then scream, “You’re a liar!” Some candidates quit on the spot; others were reduced to tears. Those who withstood the onslaught got the gig. Now Murray was ready for a more systematic study of reactions to stress. He had carefully screened students to create a sample that included a wide range of personalities and mental health profiles. He gave them code names based on their character traits, including Drill, Quartz, Locust, Hinge, and Lawful—more on him later. When students arrived for the debate, they discovered that their sparring partner was not a peer but a law student. What they didn’t know was that the law student was in cahoots with the research team: his task was to spend eighteen minutes launching an aggressive assault on their worldviews. Murray called it a “stressful interpersonal disputation,” having directed the law student to make the participants angry and anxious with a “mode of attack” that was “vehement, sweeping, and personally abusive.” The poor students sweated and shouted as they struggled to defend their ideals. The pain didn’t stop there. In the weeks that followed, the students were invited back to the lab to discuss the films of their own interactions. They watched themselves grimacing and stringing together incoherent sentences. All in all, they spent about eight hours reliving those humiliating eighteen minutes. A quarter century later, when the participants reflected on the experience, it was clear that many had found it agonizing. Drill described feeling “unabating rage.” Locust recalled his bewilderment, anger, chagrin, and discomfort. “They have deceived me, telling me there was going to be a discussion, when in fact there was an attack,” he wrote. “How could they have done this to me; what is the point of this?” Other participants had a strikingly different response: they actually seemed to get a kick out of being forced to rethink their beliefs. “Some may have found the experience mildly discomforting, in that their cherished (and in my case, at least, sophomoric) philosophies were challenged in an aggressive manner,” one participant remembers. “But it was hardly an experience that would blight one for a week, le","date":"2022-09-03","objectID":"/think_again/:8:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE DICTATOR POLICING YOUR THOUGHTS When our son was five, he was excited to learn that his uncle was expecting a child. My wife and I both predicted a boy, and so did our son. A few weeks later, we found out the baby would be a girl. When we broke the news to our son, he burst into tears. “Why are you crying?” I asked. “Is it because you were hoping your new cousin would be a boy?” “No!” he shouted, pounding his fists on the floor. “Because we were wrong!” I explained that being wrong isn’t always a bad thing. It can be a sign that we’ve learned something new—and that discovery itself can be a delight. This realization didn’t come naturally to me. Growing up, I was determined to be right. In second grade I corrected my teacher for misspelling the word lightning as lightening. When trading baseball cards I would rattle off statistics from recent games as proof that the price guide was valuing players inaccurately. My friends found this annoying and started calling me Mr. Facts. It got so bad that one day my best friend announced that he wouldn’t talk to me until I admitted I was wrong. It was the beginning of my journey to become more accepting of my own fallibility. In a classic paper, sociologist Murray Davis argued that when ideas survive, it’s not because they’re true—it’s because they’re interesting. What makes an idea interesting is that it challenges our weakly held opinions. Did you know that the moon might originally have formed inside a vaporous Earth out of magma rain? That a narwhal’s tusk is actually a tooth? When an idea or assumption doesn’t matter deeply to us, we’re often excited to question it. The natural sequence of emotions is surprise (“Really?”) followed by curiosity (“Tell me more!”) and thrill (“Whoa!”). To paraphrase a line attributed to Isaac Asimov, great discoveries often begin not with “Eureka!” but with “That’s funny . . .” When a core belief is questioned, though, we tend to shut down rather than open up. It’s as if there’s a miniature dictator living inside our heads, controlling the flow of facts to our minds, much like Kim Jong-un controls the press in North Korea. The technical term for this in psychology is the totalitarian ego, and its job is to keep out threatening information. It’s easy to see how an inner dictator comes in handy when someone attacks our character or intelligence. Those kinds of personal affronts threaten to shatter aspects of our identities that are important to us and might be difficult to change. The totalitarian ego steps in like a bodyguard for our minds, protecting our self-image by feeding us comforting lies. They’re all just jealous. You’re really, really, ridiculously good-looking. You’re on the verge of inventing the next Pet Rock. As physicist Richard Feynman quipped, “You must not fool yourself—and you are the easiest person to fool.” Our inner dictator also likes to take charge when our deeply held opinions are threatened. In the Harvard study of attacking students’ worldviews, the participant who had the strongest negative reaction was code-named Lawful. He came from a blue-collar background and was unusually precocious, having started college at sixteen and joined the study at seventeen. One of his beliefs was that technology was harming civilization, and he became hostile when his views were questioned. Lawful went on to become an academic, and when he penned his magnum opus, it was clear that he hadn’t changed his mind. His concerns about technology had only intensified: The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in “advanced” countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities . . . to physical suffering as well . . . and have inflicted severe damage on the natural world. That kind of conviction is a common response to threats. Neuroscientists find that when our core belie","date":"2022-09-03","objectID":"/think_again/:8:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"ATTACHMENT ISSUES Not long ago I gave a speech at a conference about my research on givers, takers, and matchers. I was studying whether generous, selfish, or fair people were more productive in jobs like sales and engineering. One of the attendees was Daniel Kahneman, the Nobel Prize–winning psychologist who has spent much of his career demonstrating how flawed our intuitions are. He told me afterward that he was surprised by my finding that givers had higher rates of failure than takers and matchers—but higher rates of success, too. When you read a study that surprises you, how do you react? Many people would get defensive, searching for flaws in the study’s design or the statistical analysis. Danny did the opposite. His eyes lit up, and a huge grin appeared on his face. “That was wonderful,” he said. “I was wrong.” Later, I sat down with Danny for lunch and asked him about his reaction. It looked a lot to me like the joy of being wrong—his eyes twinkled as if he was having fun. He said that in his eighty-five years, no one had pointed that out before, but yes, he genuinely enjoys discovering that he was wrong, because it means he is now less wrong than before. I knew the feeling. In college, what first attracted me to social science was reading studies that clashed with my expectations; I couldn’t wait to tell my roommates about all the assumptions I’d been rethinking. In my first independent research project, I tested some predictions of my own, and more than a dozen of my hypotheses turned out to be false.* It was a major lesson in intellectual humility, but I wasn’t devastated. I felt an immediate rush of excitement. Discovering I was wrong felt joyful because it meant I’d learned something. As Danny told me, “Being wrong is the only way I feel sure I’ve learned anything.” Danny isn’t interested in preaching, prosecuting, or politicking. He’s a scientist devoted to the truth. When I asked him how he stays in that mode, he said he refuses to let his beliefs become part of his identity. “I change my mind at a speed that drives my collaborators crazy,” he explained. “My attachment to my ideas is provisional. There’s no unconditional love for them.” Attachment. That’s what keeps us from recognizing when our opinions are off the mark and rethinking them. To unlock the joy of being wrong, we need to detach. I’ve learned that two kinds of detachment are especially useful: detaching your present from your past and detaching your opinions from your identity. Let’s start with detaching your present from your past. In psychology, one way of measuring the similarity between the person you are right now and your former self is to ask: which pair of circles best describes how you see yourself? In the moment, separating your past self from your current self can be unsettling. Even positive changes can lead to negative emotions; evolving your identity can leave you feeling derailed and disconnected. Over time, though, rethinking who you are appears to become mentally healthy—as long as you can tell a coherent story about how you got from past to present you. In one study, when people felt detached from their past selves, they became less depressed over the course of the year. When you feel as if your life is changing direction, and you’re in the process of shifting who you are, it’s easier to walk away from foolish beliefs you once held. My past self was Mr. Facts—I was too fixated on knowing. Now I’m more interested in finding out what I don’t know. As Bridgewater founder Ray Dalio told me, “If you don’t look back at yourself and think, ‘Wow, how stupid I was a year ago,’ then you must not have learned much in the last year.” The second kind of detachment is separating your opinions from your identity. I’m guessing you wouldn’t want to see a doctor whose identity is Professional Lobotomist, send your kids to a teacher whose identity is Corporal Punisher, or live in a town where the police chief’s identity is Stop-and-Frisker. Once upon","date":"2022-09-03","objectID":"/think_again/:8:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE YODA EFFECT: “YOU MUST UNLEARN WHAT YOU HAVE LEARNED” On my quest to find people who enjoy discovering they were wrong, a trusted colleague told me I had to meet Jean-Pierre Beugoms. He’s in his late forties, and he’s the sort of person who’s honest to a fault; he tells the truth even if it hurts. When his son was a toddler, they were watching a space documentary together, and Jean-Pierre casually mentioned that the sun would one day turn into a red giant and engulf the Earth. His son was not amused. Between tears, he cried, “But I love this planet!” Jean-Pierre felt so terrible that he decided to bite his tongue instead of mentioning threats that could prevent the Earth from even lasting that long. Back in the 1990s, Jean-Pierre had a hobby of collecting the predictions that pundits made on the news and scoring his own forecasts against them. Eventually he started competing in forecasting tournaments—international contests hosted by Good Judgment, where people try to predict the future. It’s a daunting task; there’s an old saying that historians can’t even predict the past. A typical tournament draws thousands of entrants from around the world to anticipate big political, economic, and technological events. The questions are time-bound, with measurable, specific results. Will the current president of Iran still be in office in six months? Which soccer team will win the next World Cup? In the following year, will an individual or a company face criminal charges for an accident involving a self-driving vehicle? Participants don’t just answer yes or no; they have to give their odds. It’s a systematic way of testing whether they know what they don’t know. They get scored months later on accuracy and calibration—earning points not just for giving the right answer, but also for having the right level of conviction. The best forecasters have confidence in their predictions that come true and doubt in their predictions that prove false. On November 18, 2015, Jean-Pierre registered a prediction that stunned his opponents. A day earlier, a new question had popped up in an open forecasting tournament: in July 2016, who would win the U.S. Republican presidential primary? The options were Jeb Bush, Ben Carson, Ted Cruz, Carly Fiorina, Marco Rubio, Donald Trump, and none of the above. With eight months to go before the Republican National Convention, Trump was largely seen as a joke. His odds of becoming the Republican nominee were only 6 percent according to Nate Silver, the celebrated statistician behind the website FiveThirtyEight. When Jean-Pierre peered into his crystal ball, though, he decided Trump had a 68 percent chance of winning. Jean-Pierre didn’t just excel in predicting the results of American events. His Brexit forecasts hovered in the 50 percent range when most of his competitors thought the referendum had little chance of passing. He successfully predicted that the incumbent would lose a presidential election in Senegal, even though the base rates of reelection were extremely high and other forecasters were expecting a decisive win. And he had, in fact, pegged Trump as the favorite long before pundits and pollsters even considered him a viable contender. “It’s striking,” Jean-Pierre wrote early on, back in 2015, that so many forecasters are “still in denial about his chances.” Based on his performance, Jean-Pierre might be the world’s best election forecaster. His advantage: he thinks like a scientist. He’s passionately dispassionate. At various points in his life, Jean-Pierre has changed his political ideologies and religious beliefs.* He doesn’t come from a polling or statistics background; he’s a military historian, which means he has no stake in the way things have always been done in forecasting. The statisticians were attached to their views about how to aggregate polls. Jean-Pierre paid more attention to factors that were hard to measure and overlooked. For Trump, those included “Mastery at manipulating the medi","date":"2022-09-03","objectID":"/think_again/:8:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"MISTAKES WERE MADE . . . MOST LIKELY BY ME As prescient as Jean-Pierre’s bet on Trump was, he still had trouble sticking to it in the face of his feelings. In the spring of 2016, he identified the media coverage of Hillary Clinton’s emails as a red flag, and kept predicting a Trump victory for two months more. By the summer, though, as he contemplated the impending possibility of a Trump presidency, he found himself struggling to sleep at night. He changed his forecast to Clinton. Looking back, Jean-Pierre isn’t defensive about his decision. He freely admits that despite being an experienced forecaster, he made the rookie mistake of falling victim to desirability bias, allowing his preference to cloud his judgment. He focused on the forces that would enable him to predict a Clinton win because he desperately wanted a Trump loss. “That was just a way of me trying to deal with this unpleasant forecast I had issued,” he says. Then he does something unexpected: he laughs at himself. If we’re insecure, we make fun of others. If we’re comfortable being wrong, we’re not afraid to poke fun at ourselves. Laughing at ourselves reminds us that although we might take our decisions seriously, we don’t have to take ourselves too seriously. Research suggests that the more frequently we make fun of ourselves, the happier we tend to be.* Instead of beating ourselves up about our mistakes, we can turn some of our past misconceptions into sources of present amusement. Being wrong won’t always be joyful. The path to embracing mistakes is full of painful moments, and we handle those moments better when we remember they’re essential for progress. But if we can’t learn to find occasional glee in discovering we were wrong, it will be awfully hard to get anything right. I’ve noticed a paradox in great scientists and superforecasters: the reason they’re so comfortable being wrong is that they’re terrified of being wrong. What sets them apart is the time horizon. They’re determined to reach the correct answer in the long run, and they know that means they have to be open to stumbling, backtracking, and rerouting in the short run. They shun rose-colored glasses in favor of a sturdy mirror. The fear of missing the mark next year is a powerful motivator to get a crystal-clear view of last year’s mistakes. “People who are right a lot listen a lot, and they change their mind a lot,” Jeff Bezos says. “If you don’t change your mind frequently, you’re going to be wrong a lot.” Jean-Pierre Beugoms has a favorite trick for catching himself when he’s wrong. When he makes a forecast, he also makes a list of the conditions in which it should hold true—as well as the conditions under which he would change his mind. He explains that this keeps him honest, preventing him from getting attached to a bad prediction. What forecasters do in tournaments is good practice in life. When you form an opinion, ask yourself what would have to happen to prove it false. Then keep track of your views so you can see when you were right, when you were wrong, and how your thinking has evolved. “I started out just wanting to prove myself,” Jean-Pierre says. “Now I want to improve myself—to see how good I can get.” It’s one thing to admit to ourselves that we’ve been wrong. It’s another thing to confess that to other people. Even if we manage to overthrow our inner dictator, we run the risk of facing outer ridicule. In some cases we fear that if others find out we were wrong, it could destroy our reputations. How do people who accept being wrong cope with that? In the early 1990s, the British physicist Andrew Lyne published a major discovery in the world’s most prestigious science journal. He presented the first evidence that a planet could orbit a neutron star—a star that had exploded into a supernova. Several months later, while preparing to give a presentation at an astronomy conference, he noticed that he hadn’t adjusted for the fact that the Earth moves in an elliptical orbit, not a c","date":"2022-09-03","objectID":"/think_again/:8:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 4 ","date":"2022-09-03","objectID":"/think_again/:9:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"The Good Fight Club ","date":"2022-09-03","objectID":"/think_again/:10:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"The Psychology of Constructive Conflict Arguments are extremely vulgar, for everybody in good society holds exactly the same opinions. —oscar wilde As the two youngest boys in a big family, the bishop’s sons did everything together. They launched a newspaper and built their own printing press together. They opened a bicycle shop and then started manufacturing their own bikes together. And after years of toiling away at a seemingly impossible problem, they invented the first successful airplane together. Wilbur and Orville Wright first caught the flying bug when their father brought home a toy helicopter. After it broke, they built one of their own. As they advanced from playing together to working together to rethinking human flight together, there was no trace of sibling rivalry between them. Wilbur even said they “thought together.” Even though it was Wilbur who launched the project, the brothers shared equal credit for their achievement. When it came time to decide who would pilot their historic flight at Kitty Hawk, they just flipped a coin. New ways of thinking often spring from old bonds. The comedic chemistry of Tina Fey and Amy Poehler can be traced back to their early twenties, when they immediately hit it off in an improv class. The musical harmony of the Beatles started even earlier, when they were in high school. Just minutes after a mutual friend introduced them, Paul McCartney was teaching John Lennon how to tune a guitar. Ben \u0026 Jerry’s Ice Cream grew out of a friendship between the two founders that began in seventh-grade gym class. It seems that to make progress together, we need to be in sync. But the truth, like all truths, is more complicated. One of the world’s leading experts on conflict is an organizational psychologist in Australia named Karen “Etty” Jehn. When you think about conflict, you’re probably picturing what Etty calls relationship conflict—personal, emotional clashes that are filled not just with friction but also with animosity. I hate your stinking guts. I’ll use small words so that you’ll be sure to understand, you warthog-faced buffoon. You bob for apples in the toilet . . . and you like it. But Etty has identified another flavor called task conflict—clashes about ideas and opinions. We have task conflict when we’re debating whom to hire, which restaurant to pick for dinner, or whether to name our child Gertrude or Quasar. The question is whether the two types of conflict have different consequences. A few years ago I surveyed hundreds of new teams in Silicon Valley on conflict several times during their first six months working together. Even if they argued constantly and agreed on nothing else, they agreed on what kind of conflict they were having. When their projects were finished, I asked their managers to evaluate each team’s effectiveness. The teams that performed poorly started with more relationship conflict than task conflict. They entered into personal feuds early on and were so busy disliking one another that they didn’t feel comfortable challenging one another. It took months for many of the teams to make real headway on their relationship issues, and by the time they did manage to debate key decisions, it was often too late to rethink their directions. What happened in the high-performing groups? As you might expect, they started with low relationship conflict and kept it low throughout their work together. That didn’t stop them from having task conflict at the outset: they didn’t hesitate to surface competing perspectives. As they resolved some of their differences of opinion, they were able to align on a direction and carry out their work until they ran into new issues to debate. All in all, more than a hundred studies have examined conflict types in over eight thousand teams. A meta-analysis of those studies showed that relationship conflict is generally bad for performance, but some task conflict can be beneficial: it’s been linked to higher creativity and smarter choices. ","date":"2022-09-03","objectID":"/think_again/:11:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE PLIGHT OF THE PEOPLE PLEASER As long as I can remember, I’ve been determined to keep the peace. Maybe it’s because my group of friends dropped me in middle school. Maybe it’s genetic. Maybe it’s because my parents got divorced. Whatever the cause, in psychology there’s a name for my affliction. It’s called agreeableness, and it’s one of the major personality traits around the world. Agreeable people tend to be nice. Friendly. Polite. Canadian.* My first impulse is to avoid even the most trivial of conflicts. When I’m riding in an Uber and the air-conditioning is blasting, I struggle to bring myself to ask the driver to turn it down—I just sit there shivering in silence until my teeth start to chatter. When someone steps on my shoe, I’ve actually apologized for inconveniently leaving my foot in his path. When students fill out course evaluations, one of their most common complaints is that I’m “too supportive of stupid comments.” Disagreeable people tend to be more critical, skeptical, and challenging—and they’re more likely than their peers to become engineers and lawyers. They’re not just comfortable with conflict; it energizes them. If you’re highly disagreeable, you might be happier in an argument than in a friendly conversation. That quality often comes with a bad rap: disagreeable people get stereotyped as curmudgeons who complain about every idea, or Dementors who suck the joy out of every meeting. When I studied Pixar, though, I came away with a dramatically different view. In 2000, Pixar was on fire. Their teams had used computers to rethink animation in their first blockbuster, Toy Story, and they were fresh off two more smash hits. Yet the company’s founders weren’t content to rest on their laurels. They recruited an outside director named Brad Bird to shake things up. Brad had just released his debut film, which was well reviewed but flopped at the box office, so he was itching to do something big and bold. When he pitched his vision, the technical leadership at Pixar said it was impossible: they would need a decade and $500 million to make it. Brad wasn’t ready to give up. He sought out the biggest misfits at Pixar for his project—people who were disagreeable, disgruntled, and dissatisfied. Some called them black sheep. Others called them pirates. When Brad rounded them up, he warned them that no one believed they could pull off the project. Just four years later, his team didn’t only succeed in releasing Pixar’s most complex film ever; they actually managed to lower the cost of production per minute. The Incredibles went on to gross upwards of $631 million worldwide and won the Oscar for Best Animated Feature. Notice what Brad didn’t do. He didn’t stock his team with agreeable people. Agreeable people make for a great support network: they’re excited to encourage us and cheerlead for us. Rethinking depends on a different kind of network: a challenge network, a group of people we trust to point out our blind spots and help us overcome our weaknesses. Their role is to activate rethinking cycles by pushing us to be humble about our expertise, doubt our knowledge, and be curious about new perspectives. The ideal members of a challenge network are disagreeable, because they’re fearless about questioning the way things have always been done and holding us accountable for thinking again. There’s evidence that disagreeable people speak up more frequently—especially when leaders aren’t receptive—and foster more task conflict. They’re like the doctor in the show House or the boss in the film The Devil Wears Prada. They give the critical feedback we might not want to hear, but need to hear. Harnessing disagreeable people isn’t always easy. It helps if certain conditions are in place. Studies in oil drilling and tech companies suggest that dissatisfaction promotes creativity only when people feel committed and supported—and that cultural misfits are most likely to add value when they have strong bonds with their colleague","date":"2022-09-03","objectID":"/think_again/:11:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"DON’T AGREE TO DISAGREE Hashing out competing views has potential downsides—risks that need to be managed. On the first Incredibles film, a rising star named Nicole Grindle had managed the simulation of the hair, watching John and Brad’s interactions from a distance. When Nicole came in to produce the sequel with John, one of her concerns was that the volume of the arguments between the two highly accomplished leaders might drown out the voices of people who were less comfortable speaking up: newcomers, introverts, women, and minorities. It’s common for people who lack power or status to shift into politician mode, suppressing their dissenting views in favor of conforming to the HIPPO—the HIghest Paid Person’s Opinion. Sometimes they have no other choice if they want to survive. To make sure their desire for approval didn’t prevent them from introducing task conflict, Nicole encouraged new people to bring their divergent ideas to the table. Some voiced them directly to the group; others went to her for feedback and support. Although Nicole wasn’t a pirate, as she found herself advocating for different perspectives she became more comfortable challenging Brad on characters and dialogue. “Brad is still the ornery guy who first came to Pixar, so you have to be ready for a spirited debate when you put forward a contrary point of view.” The notion of a spirited debate captures something important about how and why good fights happen. If you watch Brad argue with his colleagues—or the pirates fight with one another—you can quickly see that the tension is intellectual, not emotional. The tone is vigorous and feisty rather than combative or aggressive. They don’t disagree just for the sake of it; they disagree because they care. “Whether you disagree loudly, or quietly yet persistently put forward a different perspective,” Nicole explains, “we come together to support the common goal of excellence—of making great films.” After seeing their interactions up close, I finally understood what had long felt like a contradiction in my own personality: how I could be highly agreeable and still cherish a good argument. Agreeableness is about seeking social harmony, not cognitive consensus. It’s possible to disagree without being disagreeable. Although I’m terrified of hurting other people’s feelings, when it comes to challenging their thoughts, I have no fear. In fact, when I argue with someone, it’s not a display of disrespect—it’s a sign of respect. It means I value their views enough to contest them. If their opinions didn’t matter to me, I wouldn’t bother. I know I have chemistry with someone when we find it delightful to prove each other wrong. Agreeable people don’t always steer clear of conflict. They’re highly attuned to the people around them and often adapt to the norms in the room. My favorite demonstration is an experiment by my colleagues Jennifer Chatman and Sigal Barsade. Agreeable people were significantly more accommodating than disagreeable ones—as long as they were in a cooperative team. When they were assigned to a competitive team, they acted just as disagreeably as their disagreeable teammates. That’s how working with Brad Bird influenced John Walker. John’s natural tendency is to avoid conflict: at restaurants, if the waiter brings him the wrong dish, he just goes ahead and eats it anyway. “But when I’m involved in something bigger than myself,” he observes, “I feel like I have an opportunity, a responsibility really, to speak up, speak out, debate. Fight like hell when the morning whistle blows, but go out for a beer after the one at five o’clock.” That adaptability was also visible in the Wright brothers’ relationship. In Wilbur, Orville had a built-in challenge network. Wilbur was known to be highly disagreeable: he was unfazed by other people’s opinions and had a habit of pouncing on anyone else’s idea the moment it was raised. Orville was known as gentle, cheerful, and sensitive to criticism. Yet those qualities see","date":"2022-09-03","objectID":"/think_again/:11:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"GETTING HOT WITHOUT GETTING MAD A major problem with task conflict is that it often spills over into relationship conflict. One minute you’re disagreeing about how much seasoning to put on the Thanksgiving turkey, and the next minute you find yourself yelling “You smell!” Although the Wright brothers had a lifetime of experience discovering each other’s hot buttons, that didn’t mean they always kept their cool. Their last grand challenge before liftoff was their single hardest problem: designing a propeller. They knew their airplane couldn’t take flight without one, but the right kind didn’t exist. As they struggled with various approaches, they argued back and forth for hours at a time, often raising their voices. The feuding lasted for months as each took turns preaching the merits of his own solutions and prosecuting the other’s points. Eventually their younger sister, Katharine, threatened to leave the house if they didn’t stop fighting. They kept at it anyway, until one night it culminated in what might have been the loudest shouting match of their lives. Strangely, the next morning, they came into the shop and acted as if nothing had happened. They picked up the argument about the propeller right where they had left off—only now without the yelling. Soon they were both rethinking their assumptions and stumbling onto what would become one of their biggest breakthroughs. The Wright brothers were masters at having intense task conflict without relationship conflict. When they raised their voices, it reflected intensity rather than hostility. As their mechanic marveled, “I don’t think they really got mad, but they sure got awfully hot.” Experiments show that simply framing a dispute as a debate rather than as a disagreement signals that you’re receptive to considering dissenting opinions and changing your mind, which in turn motivates the other person to share more information with you. A disagreement feels personal and potentially hostile; we expect a debate to be about ideas, not emotions. Starting a disagreement by asking, “Can we debate?” sends a message that you want to think like a scientist, not a preacher or a prosecutor—and encourages the other person to think that way, too. The Wright brothers had the benefit of growing up in a family where disagreements were seen as productive and enjoyable. When arguing with others, though, they often had to go out of their way to reframe their behavior. “Honest argument is merely a process of mutually picking the beams and motes out of each other’s eyes so both can see clearly,” Wilbur once wrote to a colleague whose ego was bruised after a fiery exchange about aeronautics. Wilbur stressed that it wasn’t personal: he saw arguments as opportunities to test and refine their thinking. “I see that you are back at your old trick of giving up before you are half beaten in an argument. I feel pretty certain of my own ground but was anticipating the pleasure of a good scrap before the matter was settled. Discussion brings out new ways of looking at things.” When they argued about the propeller, the Wright brothers were making a common mistake. Each was preaching about why he was right and why the other was wrong. When we argue about why, we run the risk of becoming emotionally attached to our positions and dismissive of the other side’s. We’re more likely to have a good fight if we argue about how. When social scientists asked people why they favor particular policies on taxes, health care, or nuclear sanctions, they often doubled down on their convictions. Asking people to explain how those policies would work in practice—or how they’d explain them to an expert—activated a rethinking cycle. They noticed gaps in their knowledge, doubted their conclusions, and became less extreme; they were now more curious about alternative options. Psychologists find that many of us are vulnerable to an illusion of explanatory depth. Take everyday objects like a bicycle, a piano, or earbuds: how well d","date":"2022-09-03","objectID":"/think_again/:11:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 5 ","date":"2022-09-03","objectID":"/think_again/:12:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Dances with Foes ","date":"2022-09-03","objectID":"/think_again/:13:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"How to Win Debates and Influence People Exhausting someone in argument is not the same as convincing him. —tim kreider At thirty-one, Harish Natarajan has won three dozen international debate tournaments. He’s been told it’s a world record. But his opponent today presents a unique challenge. Debra Jo Prectet is a prodigy hailing from Haifa, Israel. She’s just eight years old, and although she made her first foray into public debating only last summer, she’s been preparing for this moment for years. Debra has absorbed countless articles to accumulate knowledge, closely studied speechwriting to hone her clarity, and even practiced her delivery to incorporate humor. Now she’s ready to challenge the champion himself. Her parents are hoping she’ll make history. Harish was a wunderkind too. By the time he was eight, he was outmaneuvering his own parents in dinner-table debates about the Indian caste system. He went on to become the European debate champion and a grand finalist in the world debate championship, and coached the Filipino national school debate team at the world championship. I was introduced to Harish by an unusually bright former student who used to compete against him, and remembers having lost “many (likely all)” of their debates. Harish and Debra are facing off in San Francisco in February 2019 in front of a large crowd. They’ve been kept in the dark about the debate topic. When they walk onstage, the moderator announces the subject: should preschools be subsidized by the government? After just fifteen minutes of preparation, Debra will present her strongest arguments in favor of subsidies, and Harish will marshal his best case against them. Their goal is to win the audience over to their side on preschool subsidies, but their impact on me will be much broader: they’ll end up changing my view of what it takes to win a debate. Debra kicks off with a joke, drawing laughter from the crowd by telling Harish that although he may hold the world record in debate wins, he’s never debated someone like her. Then she goes on to summarize an impressive number of studies—citing her sources—about the academic, social, and professional benefits of preschool programs. For good measure, she quotes a former prime minister’s argument about preschool being a smart investment. Harish acknowledges the facts that Debra presented, but then makes his case that subsidizing preschools is not the appropriate remedy for the damage caused by poverty. He suggests that the issue should be evaluated on two grounds: whether preschool is currently underprovided and underconsumed, and whether it helps those who are the least fortunate. He argues that in a world full of trade-offs, subsidizing preschool is not the best use of taxpayer money. Going into the debate, 92 percent of the audience has already made up their minds. I’m one of them: it didn’t take me long to figure out where I stood on preschool subsidies. In the United States, public education is free from kindergarten through high school. I’m familiar with evidence that early access to education in the first few years of children’s lives may be even more critical to helping them escape poverty than anything they learn later. I believe education is a fundamental human right, like access to water, food, shelter, and health care. That puts me on Team Debra. As I watch the debate, her early arguments strike a chord. Here are some highlights: Debra: Research clearly shows that a good preschool can help kids overcome the disadvantages often associated with poverty. Data for the win! Be still, my beating heart. Debra: You will possibly hear my opponent talk today about different priorities . . . he might say that subsidies are needed, but not for preschools. I would like to ask you, Mr. Natarajan . . . why don’t we examine the evidence and the data and decide accordingly? If Harish has an Achilles’ heel, my former student has told me, it’s that his brilliant arguments aren’t always grounded in facts","date":"2022-09-03","objectID":"/think_again/:14:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE SCIENCE OF THE DEAL A few years ago a former student named Jamie called me for advice on where to go to business school. Since she was already well on her way to building a successful career, I told her it was a waste of time and money. I walked her through the lack of evidence that a graduate degree would make a tangible difference in her future, and the risk that she’d end up overqualified and underexperienced. When she insisted that her employer expected an MBA for promotions, I told her that I knew of exceptions and pointed out that she probably wouldn’t spend her whole career at that firm anyway. Finally, she hit back: “You’re a logic bully!” A what? “A logic bully,” Jamie repeated. “You just overwhelmed me with rational arguments, and I don’t agree with them, but I can’t fight back.” At first I was delighted by the label. It felt like a solid description of one of my roles as a social scientist: to win debates with the best data. Then Jamie explained that my approach wasn’t actually helpful. The more forcefully I argued, the more she dug in her heels. Suddenly I realized I had instigated that same kind of resistance many times before. David Sipress/The New Yorker Collection/The Cartoon Bank; © Condé Nast Growing up, I was taught by my karate sensei never to start a fight unless I was prepared to be the only one standing at the end. That’s how I approached debates at work and with friends: I thought the key to victory was to go into battle armed with airtight logic and rigorous data. The harder I attacked, though, the harder my opponents fought back. I was laser-focused on convincing them to accept my views and rethink theirs, but I was coming across like a preacher and a prosecutor. Although those mindsets sometimes motivated me to persist in making my points, I often ended up alienating my audience. I was not winning. For centuries, debating has been prized as an art form, but there’s now a growing science of how to do it well. In a formal debate your goal is to change the mind of your audience. In an informal debate, you’re trying to change the mind of your conversation partner. That’s a kind of negotiation, where you’re trying to reach an agreement about the truth. To build my knowledge and skills about how to win debates, I studied the psychology of negotiations and eventually used what I’d learned to teach bargaining skills to leaders across business and government. I came away convinced that my instincts—and what I’d learned in karate—were dead wrong. A good debate is not a war. It’s not even a tug-of-war, where you can drag your opponent to your side if you pull hard enough on the rope. It’s more like a dance that hasn’t been choreographed, negotiated with a partner who has a different set of steps in mind. If you try too hard to lead, your partner will resist. If you can adapt your moves to hers, and get her to do the same, you’re more likely to end up in rhythm. In a classic study, a team of researchers led by Neil Rackham examined what expert negotiators do differently. They recruited one group of average negotiators and another group of highly skilled ones, who had significant track records of success and had been rated as effective by their counterparts. To compare the participants’ techniques, they recorded both groups doing labor and contract negotiations. In a war, our goal is to gain ground rather than lose it, so we’re often afraid to surrender a few battles. In a negotiation, agreeing with someone else’s argument is disarming. The experts recognized that in their dance they couldn’t stand still and expect the other person to make all the moves. To get in harmony, they needed to step back from time to time. One difference was visible before anyone even arrived at the bargaining table. Prior to the negotiations, the researchers interviewed both groups about their plans. The average negotiators went in armed for battle, hardly taking note of any anticipated areas of agreement. The experts, in contrast,","date":"2022-09-03","objectID":"/think_again/:14:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"DANCING TO THE SAME BEAT Since the audience started out favoring preschool subsidies, there was more room for change in Harish’s direction—but he also had the more difficult task of advocating for the unpopular position. He opened the audience’s mind by taking a page out of the playbook of expert negotiators. Harish started by emphasizing common ground. When he took the stage for his rebuttal, he immediately drew attention to his and Debra’s areas of agreement. “So,” he began, “I think we disagree on far less than it may seem.” He called out their alignment on the problem of poverty—and on the validity of some of the studies—before objecting to subsidies as a solution. We won’t have much luck changing other people’s minds if we refuse to change ours. We can demonstrate openness by acknowledging where we agree with our critics and even what we’ve learned from them. Then, when we ask what views they might be willing to revise, we’re not hypocrites. Convincing other people to think again isn’t just about making a good argument—it’s about establishing that we have the right motives in doing so. When we concede that someone else has made a good point, we signal that we’re not preachers, prosecutors, or politicians trying to advance an agenda. We’re scientists trying to get to the truth. “Arguments are often far more combative and adversarial than they need to be,” Harish told me. “You should be willing to listen to what someone else is saying and give them a lot of credit for it. It makes you sound like a reasonable person who is taking everything into account.” Being reasonable literally means that we can be reasoned with, that we’re open to evolving our views in light of logic and data. So in the debate with Harish, why did Debra neglect to do that—why did she overlook common ground? It’s not because Debra is eight years old. It’s because she isn’t human. Debra Jo Prectet is an anagram I invented. Her official name is Project Debater, and she’s a machine. More specifically, an artificial intelligence developed by IBM to do for debate what Watson did for chess. They first dreamed the idea up in 2011 and started working intensively on it in 2014. Just a few years later, Project Debater had developed the remarkable ability to conduct an intelligent debate in public, complete with facts, coherent sentences, and even counterarguments. Her knowledge corpus consists of 400 million articles, largely from credible newspapers and magazines, and her claim detection engine is designed to locate key arguments, identify their boundaries, and weigh the evidence. For any debate topic, she can instantaneously search her knowledge graph for relevant data points, mold them into a logical case, and deliver it clearly—even entertainingly—in a female voice within the time constraints. Her first words in the preschool subsidy debate were, “Greetings, Harish. I’ve heard you hold the world record in debate competition wins against humans, but I suspect you’ve never debated a machine. Welcome to the future.” Of course, it’s possible that Harish won because the audience was biased against the computer and rooting for the human. It’s worth noting, though, that Harish’s approach in that debate is the same one that he’s used to defeat countless humans on international stages. What amazes me is that the computer was able to master multiple complex capabilities while completely missing this crucial one. After studying 10 billion sentences, a computer was able to say something funny—a skill that’s normally thought to be confined to sentient beings with high levels of social and emotional intelligence. The computer had learned to make a logical argument and even anticipate the other side’s counterargument. Yet it hadn’t learned to agree with elements of the other side’s argument, apparently because that behavior was all too rarely deployed across 400 million articles by humans. They were usually too busy preaching their arguments, prosecuting their enemies, or po","date":"2022-09-03","objectID":"/think_again/:14:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"DON’T STEP ON THEIR TOES Harish’s next advantage stemmed from one of his disadvantages. He would never have access to as many facts as the computer. When the audience was polled afterward about who taught them more, the overwhelming majority said they learned more from the computer than from Harish. But it was Harish who succeeded in swaying their opinions. Why? The computer piled on study after study to support a long list of reasons in favor of preschool subsidies. Like a skilled negotiator, Harish focused on just two reasons against them. He knew that making too many points could come at the cost of developing, elaborating, and reinforcing his best ones. “If you have too many arguments, you’ll dilute the power of each and every one,” he told me. “They are going to be less well explained, and I don’t know if any of them will land enough—I don’t think the audience will believe them to be important enough. Most top debaters aren’t citing a lot of information.” Is this always the best way to approach a debate? The answer is—like pretty much everything else in social science—it depends. The ideal number of reasons varies from one circumstance to another. There are times when preaching and prosecuting can make us more persuasive. Research suggests that the effectiveness of these approaches hinges on three key factors: how much people care about the issue, how open they are to our particular argument, and how strong-willed they are in general. If they’re not invested in the issue or they’re receptive to our perspective, more reasons can help: people tend to see quantity as a sign of quality. The more the topic matters to them, the more the quality of reasons matters. It’s when audiences are skeptical of our view, have a stake in the issue, and tend to be stubborn that piling on justifications is most likely to backfire. If they’re resistant to rethinking, more reasons simply give them more ammunition to shoot our views down. It’s not just about the number of reasons, though. It’s also how they fit together. A university once approached me to see if I could bring in donations from alumni who had never given a dime. My colleagues and I ran an experiment testing two different messages meant to convince thousands of resistant alumni to give. One message emphasized the opportunity to do good: donating would benefit students, faculty, and staff. The other emphasized the opportunity to feel good: donors would enjoy the warm glow of giving. The two messages were equally effective: in both cases, 6.5 percent of the stingy alumni ended up donating. Then we combined them, because two reasons are better than one. Except they weren’t. When we put the two reasons together, the giving rate dropped below 3 percent. Each reason alone was more than twice as effective as the two combined. The audience was already skeptical. When we gave them different kinds of reasons to donate, we triggered their awareness that someone was trying to persuade them—and they shielded themselves against it. A single line of argument feels like a conversation; multiple lines of argument can become an onslaught. The audience tuned out the preacher and summoned their best defense attorney to refute the prosecutor. As important as the quantity and quality of reasons might be, the source matters, too. And the most convincing source is often the one closest to your audience. A student in one of my classes, Rachel Breuhaus, noticed that although top college basketball teams have rabid fans, there are usually empty seats in their arenas. To study strategies for motivating more fans to show up, we launched an experiment in the week before an upcoming game targeting hundreds of season ticket holders. When left to their own devices, 77 percent of these supposedly die-hard fans actually made it to the game. We decided that the most persuasive message would come from the team itself, so we sent fans an email with quotes from players and coaches about how part of the home-court adva","date":"2022-09-03","objectID":"/think_again/:14:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"DR. JEKYLL AND MR. HOSTILE Some years ago, a Wall Street firm brought me in to consult on a project to attract and retain junior analysts and associates. After two months of research I submitted a report with twenty-six data-driven recommendations. In the middle of my presentation to the leadership team, one of the members interrupted and asked, “Why don’t we just pay them more?” I told him money alone probably wouldn’t make a difference. Many studies across a range of industries have shown that once people are earning enough to meet their basic needs, paying them more doesn’t stop them from leaving bad jobs and bad bosses. The executive started arguing with me: “That’s not what I’ve found in my experience.” I fired back in prosecutor mode: “Yes, that’s why I brought you randomized, controlled experiments with longitudinal data: to learn rigorously from many people’s experiences, not idiosyncratically from yours.” The executive pushed back, insisting that his company was different, so I rattled off some basic statistics from his own employees. In surveys and interviews, a grand total of zero had even mentioned compensation. They were already well paid (read: overpaid), and if that could have solved the problem, it already would have.* But the executive still refused to budge. Finally I became so exasperated that I did something out of character. I shot back, “I’ve never seen a group of smart people act so dumb.” In the hierarchy of disagreement created by computer scientist Paul Graham, the highest form of argument is refuting the central point, and the lowest is name-calling. In a matter of seconds I’d devolved from logic bully to playground bully. If I could do that session over, I’d start with common ground and fewer data points. Instead of attacking their beliefs with my research, I’d ask them what would open their minds to my data. A few years later, I had a chance to test that approach. During a keynote speech on creativity, I cited evidence that Beethoven and Mozart didn’t have higher hit rates than some of their peers; they generated a larger volume of work, which gave them more shots at greatness. A member of the audience interrupted. “Bullsh*t!” he shouted. “You’re disrespecting the great masters of music. You’re totally ignorant—you don’t know what you’re talking about!” Instead of reacting right then, I waited a few minutes until a scheduled break and then made my way to my heckler. Me: You’re welcome to disagree with the data, but I don’t think that’s a respectful way to express your opinion. It’s not how I was trained to have an intellectual debate. Were you? Music man: Well, no . . . I just think you’re wrong. Me: It’s not my opinion—it’s the independent finding of two different social scientists. What evidence would change your mind? Music man: I don’t believe you can quantify a musician’s greatness, but I’d like to see the research. When I sent him the study, he responded with an apology. I don’t know if I succeeded in changing his mind, but I had done a better job of opening it. When someone becomes hostile, if you respond by viewing the argument as a war, you can either attack or retreat. If instead you treat it as a dance, you have another option—you can sidestep. Having a conversation about the conversation shifts attention away from the substance of the disagreement and toward the process for having a dialogue. The more anger and hostility the other person expresses, the more curiosity and interest you show. When someone is losing control, your tranquility is a sign of strength. It takes the wind out of their emotional sails. It’s pretty rare for someone to respond by screaming “SCREAMING IS MY PREFERRED MODE OF COMMUNICATION!” This is a fifth move that expert negotiators made more often than average negotiators. They were more likely to comment on their feelings about the process and test their understanding of the other side’s feelings: I’m disappointed in the way this discussion has unfolded—are you fr","date":"2022-09-03","objectID":"/think_again/:14:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE STRENGTH OF WEAK OPINIONS When we hit a brick wall in a debate, we don’t have to stop talking altogether. “Let’s agree to disagree” shouldn’t end a discussion. It should start a new conversation, with a focus on understanding and learning rather than arguing and persuading. That’s what we’d do in scientist mode: take the long view and ask how we could have handled the debate more effectively. Doing so might land us in a better position to make the same case to a different person—or to make a different case to the same person on a different day. When I asked one of the Wall Street executives for advice on how to approach debates differently in the future, he suggested expressing less conviction. I could easily have countered that I was uncertain about which of my twenty-six recommendations might be relevant. I could also have conceded that although money didn’t usually solve the problem, I’d never seen anyone test the effect of million-dollar retention bonuses. That would be a fun experiment to run, don’t you think? A few years ago, I argued in my book Originals that if we want to fight groupthink, it helps to have “strong opinions, weakly held.” Since then I’ve changed my mind—I now believe that’s a mistake. If we hold an opinion weakly, expressing it strongly can backfire. Communicating it with some uncertainty signals confident humility, invites curiosity, and leads to a more nuanced discussion. Research shows that in courtrooms, expert witnesses and deliberating jurors are more credible and more persuasive when they express moderate confidence, rather than high or low confidence.* And these principles aren’t limited to debates—they apply in a wide range of situations where we’re advocating for our beliefs or even for ourselves. In 2014, a young woman named Michele Hansen came across a job opening for a product manager at an investment company. She was excited about the position but she wasn’t qualified for it: she had no background in finance and lacked the required number of years of experience. If you were in her shoes and you decided to go for it, what would you say in your cover letter? The natural starting point would be to emphasize your strengths and downplay your weaknesses. As Michael Scott deadpanned on The Office, “I work too hard, I care too much, and sometimes I can be too invested in my job.” But Michele Hansen did the opposite, taking a page out of the George Costanza playbook on Seinfeld: “My name is George. I’m unemployed and I live with my parents.” Rather than trying to hide her shortcomings, Michele opened with them. “I’m probably not the candidate you’ve been envisioning,” her cover letter began. “I don’t have a decade of experience as a Product Manager nor am I a Certified Financial Planner.” After establishing the drawbacks of her case, she emphasized a few reasons to hire her anyway: But what I do have are skills that can’t be taught. I take ownership of projects far beyond my pay grade and what is in my defined scope of responsibilities. I don’t wait for people to tell me what to do and go seek for myself what needs to be done. I invest myself deeply in my projects and it shows in everything I do, from my projects at work to my projects that I undertake on my own time at night. I’m entrepreneurial, I get things done, and I know I would make an excellent right hand for the co-founder leading this project. I love breaking new ground and starting with a blank slate. (And any of my previous bosses would be able to attest to these traits.) A week later a recruiter contacted her for a phone screen, and then she had another phone screen with the team. On the calls, she asked about experiments they’d run recently that had surprised them. The question itself surprised the team—they ended up talking about times when they were sure they were right but were later proven wrong. Michele got the job, thrived, and was promoted to lead product development. This success isn’t unique to her: there’s evidence that ","date":"2022-09-03","objectID":"/think_again/:14:5","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 6 ","date":"2022-09-03","objectID":"/think_again/:15:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Bad Blood on the Diamond ","date":"2022-09-03","objectID":"/think_again/:16:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Diminishing Prejudice by Destabilizing Stereotypes I hated the Yankees with all my heart, even to the point of having to confess in my first holy confession that I wished harm to others—namely that I wished various New York Yankees would break arms, legs and ankles. . . . —doris kearns goodwin One afternoon in Maryland in 1983, Daryl Davis arrived at a lounge to play the piano at a country music gig. It wasn’t his first time being the only Black man in the room. Before the night was out, it would be his first time having a conversation with a white supremacist. After the show, an older white man in the audience walked up to Daryl and told him that he was astonished to see a Black musician play like Jerry Lee Lewis. Daryl replied that he and Lewis were, in fact, friends, and that Lewis himself had acknowledged that his style was influenced by Black musicians. Although the man was skeptical, he invited Daryl to sit down for a drink. Soon the man was admitting that he’d never had a drink with a Black person before. Eventually he explained to Daryl why. He was a member of the Ku Klux Klan, the white supremacist hate group that had been murdering African Americans for over a century and had lynched a man just two years earlier. If you found yourself sitting down with someone who hated you and all people who shared your skin color, your instinctive options might be fight, flight, or freeze—and rightfully so. Daryl had a different reaction: he burst out laughing. When the man pulled out his KKK membership card to show he wasn’t joking, Daryl returned to a question that had been on his mind since he was ten years old. In the late 1960s, he was marching in a Cub Scout parade when white spectators started throwing cans, rocks, and bottles at him. It was the first time he remembers facing overt racism, and although he could justifiably have gotten angry, he was bewildered: “How can you hate me when you don’t even know me?” At the end of the conversation, the Klansman handed Daryl his phone number and asked if he would call him whenever he was playing locally. Daryl followed up, and the next month the man showed up with a bunch of his friends to see Daryl perform. Over time a friendship grew, and the man ended up leaving the KKK. That was a turning point in Daryl’s life, too. It wasn’t long before Daryl was sitting down with Imperial Wizards and Grand Dragons—the Klan’s highest officers—to ask his question. Since then, Daryl has convinced many white supremacists to leave the KKK and abandon their hatred. I wanted to understand how that kind of change happens—how to break overconfidence cycles that are steeped in stereotypes and prejudice about entire groups of people. Strangely enough, my journey started at a baseball game. ","date":"2022-09-03","objectID":"/think_again/:17:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"HATE ME OUT AT THE BALLGAME “Yankees suck! Yankees suck!” It was a summer night at Fenway Park, my first and only time at a Boston Red Sox baseball game. In the seventh inning, without warning, 37,000 people erupted into a chant. The entire stadium was dissing the New York Yankees in perfect harmony. I knew the two teams had a century-long rivalry, widely viewed as the most heated in all of American professional sports. I took it for granted that the Boston fans would root against the Yankees. I just didn’t expect it to happen that day, because the Yankees weren’t even there. The Red Sox were playing against the Oakland A’s. The Boston fans were booing a team that was hundreds of miles away. It was as if Burger King fans were going head-to-head against Wendy’s in a taste test and started chanting “McDonald’s sucks!” I started to wonder if Red Sox fans hate the Yankees more than they love their own team. Boston parents have been known to teach their kids to flip the bird at the Yankees and detest anything in pinstripes, and yankees suck is apparently among the most popular T-shirts in Boston history. When asked how much money it would take to get them to taunt their own team, Red Sox fans requested an average of $503. To root for the Yankees, they wanted even more: $560. The feelings run so deep that neuroscientists can watch them light up people’s minds: when Red Sox fans see the Yankees fail, they show immediate activation in brain regions linked to reward and pleasure. Those feelings extend well beyond Boston: in a 2019 analysis of tweets, the Yankees were the most hated baseball team in twenty-eight of the fifty U.S. states, which may explain the popularity of this T-shirt: I recently called a friend who’s a die-hard Red Sox fan with a simple question: what would it take to get him to root for the Yankees? Without pausing, he said, “If they were playing Al Qaeda . . . maybe.” It’s one thing to love your team. It’s another to hate your rivals so much that you’d consider rooting for terrorists to crush them. If you despise a particular sports team—and its fans—you’re harboring some strong opinions about a group of people. Those beliefs are stereotypes, and they often spill over into prejudice. The stronger your attitudes become, the less likely you are to rethink them. Rivalries aren’t unique to sports. A rivalry exists whenever we reserve special animosity for a group we see as competing with us for resources or threatening our identities. In business, the rivalry between footwear companies Puma and Adidas was so intense that for generations, families self-segregated based on their allegiance to the brands—they went to different bakeries, pubs, and shops, and even refused to date people who worked for the rival firm. In politics, you probably know some Democrats who view Republicans as being greedy, ignorant, heartless cretins, and some Republicans who regard Democrats as lazy, dishonest, hypersensitive snowflakes. As stereotypes stick and prejudice deepens, we don’t just identify with our own group; we disidentify with our adversaries, coming to define who we are by what we’re not. We don’t just preach the virtues of our side; we find self-worth in prosecuting the vices of our rivals. When people hold prejudice toward a rival group, they’re often willing to do whatever it takes to elevate their own group and undermine their rivals—even if it means doing harm or doing wrong. We see people cross those lines regularly in sports rivalries.* Aggression extends well beyond the playing field: from Barcelona to Brazil, fistfights frequently break out between soccer fans. Cheating scandals are rampant, too, and they aren’t limited to athletes or coaches. When students at The Ohio State University were paid to participate in an experiment, they learned that if they were willing to lie to a student from a different school, their own pay would double and the other student’s compensation would be cut in half. Their odds of lying quadrup","date":"2022-09-03","objectID":"/think_again/:17:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"FITTING IN AND STANDING OUT For decades psychologists have found that people can feel animosity toward other groups even when the boundaries between them are trivial. Take a seemingly innocuous question: is a hot dog a sandwich? When students answered this question, most felt strongly enough that they were willing to sacrifice a dollar to those who agreed with them to make sure those who disagreed got less. In every human society, people are motivated to seek belonging and status. Identifying with a group checks both boxes at the same time: we become part of a tribe, and we take pride when our tribe wins. In classic studies on college campuses, psychologists found that after their team won a football game, students were more likely to walk around wearing school swag. From Arizona State to Notre Dame to USC, students basked in the reflected glory of Saturday victories, donning team shirts and hats and jackets on Sunday. If their team lost, they shunned school apparel, and distanced themselves by saying “they lost” instead of “we lost.” Some economists and finance experts have even found that the stock market rises if a country’s soccer team wins World Cup matches and falls if they lose.* Rivalries are most likely to develop between teams that are geographically close, compete regularly, and are evenly matched. The Yankees and Red Sox fit this pattern: they’re both on the East Coast, they play each other eighteen or nineteen times a season, they both have histories of success, and as of 2019, they had competed over 2,200 times—with each team winning over 1,000 times. The two teams also have more fans than any other franchises in baseball. I decided to test what it would take to get fans to rethink their beliefs about their bitter rivals. Working with a doctoral student, Tim Kundro, I ran a series of experiments with passionate Yankees and Red Sox supporters. To get a sense of their stereotypes, we asked over a thousand Red Sox and Yankees fans to list three negative things about their rivals. They mostly used the same words to describe one another, complaining about their respective accents, their beards, and their tendency to “smell like old corn chips.” WHY RED SOX FANS HATE YANKEES FANS WHY YANKEES FANS HATE RED SOX FANS Once we’ve formed those kinds of stereotypes, for both mental and social reasons it’s hard to undo them. Psychologist George Kelly observed that our beliefs are like pairs of reality goggles. We use them to make sense of the world and navigate our surroundings. A threat to our opinions cracks our goggles, leaving our vision blurred. It’s only natural to put up our guard in response—and Kelly noticed that we become especially hostile when trying to defend opinions that we know, deep down, are false. Rather than trying on a different pair of goggles, we become mental contortionists, twisting and turning until we find an angle of vision that keeps our current views intact. Socially, there’s another reason stereotypes are so sticky. We tend to interact with people who share them, which makes them even more extreme. This phenomenon is called group polarization, and it’s been demonstrated in hundreds of experiments. Juries with authoritarian beliefs recommend harsher punishments after deliberating together. Corporate boards are more likely to support paying outlandish premiums for companies after group discussions. Citizens who start out with a clear belief on affirmative action and gay marriage develop more extreme views on these issues after talking with a few others who share their stance. Their preaching and prosecuting move in the direction of their politics. Polarization is reinforced by conformity: peripheral members fit in and gain status by following the lead of the most prototypical member of the group, who often holds the most intense views. Grow up in a family of Red Sox fans and you’re bound to hear some unpleasant things about Yankees fans. Start making regular trips to a ballpark packed with people w","date":"2022-09-03","objectID":"/think_again/:17:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"HYPOTHESIS 1: NOT IN A LEAGUE OF THEIR OWN If you ever leave the planet Earth, you’ll probably end up rethinking some of your feelings about other human beings. A team of psychologists has studied the effects of outer space on inner space, assessing the changes in more than a hundred astronauts and cosmonauts through interviews, surveys, and analyses of autobiographies. Upon returning from space, astronauts are less focused on individual achievements and personal happiness, and more concerned about the collective good. “You develop an instant global consciousness . . . an intense dissatisfaction with the state of the world, and a compulsion to do something about it,” Apollo 14 astronaut Edgar Mitchell reflected. “From out there on the moon, international politics looks so petty. You want to grab a politician by the scruff of the neck and drag him a quarter of a million miles out and say, ‘Look at that, you son of a b*tch.’” This reaction is known as the overview effect. The astronaut who described it most vividly to me is space shuttle commander Jeff Ashby. He recalled that the first time he looked back at the Earth from outer space, it changed him forever: On Earth, astronauts look to the stars—most of us are star fanatics—but in space, the stars look the same as they do on Earth. What is so different is the planet—the perspective that it gives you. My first glimpse of the Earth from space was about fifteen minutes into my first flight, when I looked up from my checklist and suddenly we were over the lit part of the Earth with our windows facing down. Below me was the continent of Africa, and it was moving by much as a city would move by from an airline seat. Circling the entire planet in ninety minutes, you see that thin blue arc of the atmosphere. Seeing how fragile the little layer is in which all of humankind exists, you can easily from space see the connection between someone on one side of the planet to someone on the other—and there are no borders evident. So it appears as just this one common layer that we all exist in. When you get to see an overview of the Earth from outer space, you realize you share a common identity with all human beings. I wanted to create a version of the overview effect for baseball fans. There’s some evidence that common identity can build bridges between rivals. In one experiment, psychologists randomly assigned Manchester United soccer fans a short writing task. They then staged an emergency in which a passing runner slipped and fell, screaming in pain as he held his ankle. He was wearing the T-shirt of their biggest rival, and the question was whether they would stop to help him. If the soccer fans had just written about why they loved their team, only 30 percent helped. If they had written about what they had in common with other soccer fans, 70 percent helped. When Tim and I tried to get Red Sox and Yankees fans to reflect on their common identity as baseball fans, it didn’t work. They didn’t end up with more positive views of one another or a greater willingness to help one another outside emergency situations. Shared identity doesn’t stick in every circumstance. If a rival fan has just had an accident, thinking about a common identity might motivate us to help. If he’s not in danger or dire need, though, it’s too easy to dismiss him as just another jerk—or not our responsibility. “We both love baseball,” one Red Sox supporter commented. “The Yankees fans just like the wrong team.” Another stated that their shared love of baseball had no effect on his opinions: “The Yankees suck, and their fans are annoying.” ","date":"2022-09-03","objectID":"/think_again/:17:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"HYPOTHESIS 2: FEELING FOR OUR FOES I next turned to the psychology of peace. Years ago the pioneering psychologist and Holocaust survivor Herb Kelman set out to challenge some of the stereotypes behind the Israel-Palestine conflict by teaching the two sides to understand and empathize with one another. He designed interactive problem-solving workshops in which influential Israeli and Palestinian leaders talked off the record about paths to peace. For years, they came together to share their own experiences and perspectives, address one another’s needs and fears, and explore novel solutions to the conflict. Over time, the workshops didn’t just shatter stereotypes—some of the participants ended up forming lifelong friendships. Humanizing the other side should be much easier in sports, because the stakes are lower and the playing field is more level. I started with another of the biggest rivalries in sports: UNC-Duke. I asked Shane Battier, who led Duke to an NCAA basketball championship in 2001, what it would take for him to root for UNC. His immediate reply: “If they were playing the Taliban.” I had no idea so many people fantasized about crushing terrorists in their favorite sport. I wondered whether humanizing a Duke student would change UNC students’ stereotypes of the group. In an experiment with my colleagues Alison Fragale and Karren Knowlton, we asked UNC students to help improve the job application of a peer. If we mentioned that he went to Duke rather than UNC, as long as he was facing significant financial need, participants spent extra time helping him. Once they felt empathy for his plight, they saw him as a unique individual deserving of assistance and liked him more. Yet when we measured their views of Duke students in general, the UNC students were just as likely to see them as their rivals, to say that it felt like a personal compliment if they heard someone criticize Duke, and to take it as a personal insult if they heard Duke praised. We had succeeded in changing their attitudes toward the student, but failed in changing their stereotypes of the group. Something similar happened when Tim and I tried to humanize a Yankees fan. We had Red Sox fans read a story written by a baseball buff who had learned the game as a child with his grandfather and had fond memories of playing catch with his mom. At the very end of the piece he mentioned that he was a die-hard supporter of the Yankees. “I think this person is very authentic and is a rare Yankee fan,” one Red Sox supporter commented. “This person gets it and is not your typical Yankee fan,” a second observed. “Ugh, I really liked this text until I got to the part about them being a Yankees fan,” a third fan lamented, but “I think this particular person I would have more in common with than the typical, stereotypical Yankees fan. This person is okay.” Herb Kelman ran into the same problem with Israelis and Palestinians. In the problem-solving workshops, they came to trust the individuals across the table, but they still held on to their stereotypes of the group. In an ideal world, learning about individual group members will humanize the group, but often getting to know a person better just establishes her as different from the rest of her group. When we meet group members who defy a stereotype, our first instinct isn’t to see them as exemplars and rethink the stereotype. It’s to see them as exceptions and cling to our existing beliefs. So that attempt also failed. Back to the drawing board again. ","date":"2022-09-03","objectID":"/think_again/:17:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"HYPOTHESIS 3: BEASTS OF HABIT My all-time favorite commercial starts with a close-up of a man and a woman kissing. As the camera zooms out, you see that he’s wearing an Ohio State Buckeyes sweatshirt and she’s wearing a Michigan Wolverines T-shirt. The caption: “Without sports, this wouldn’t be disgusting.” As a lifelong Wolverine fan, I was raised to boo at Buckeye fans. My uncle filled his basement with Michigan paraphernalia, got up at 3:00 a.m. on Saturdays to start setting up for tailgates, and drove a van with the Michigan logo emblazoned on the side. When I went back home to Michigan for grad school and one of my college roommates started medical school at Ohio State, it was only natural for me to preach my school’s superiority by phone and prosecute his intelligence by text. A few years ago, I got to know an unusually kind woman in her seventies who works with Holocaust survivors. Last summer, when she mentioned that she had gone to Ohio State, my first response was “yuck.” My next reaction was to be disgusted with myself. Who cares where she went to school half a century ago? How did I get programmed this way? Suddenly it seemed odd that anyone would hate a team at all. In ancient Greece, Plutarch wrote of a wooden ship that Theseus sailed from Crete to Athens. To preserve the ship, as its old planks decayed, Athenians would replace them with new wood. Eventually all the planks had been replaced. It looked like the same ship, but none of its parts was the same. Was it still the same ship? Later, philosophers added a wrinkle: if you collected all the original planks and fashioned them into a ship, would that be the same ship? The ship of Theseus has a lot in common with a sports franchise. If you hail from Boston, you might hate the 1920 Yankees for taking Babe Ruth or the 1978 Yankees for dashing your World Series hopes. Although the current team carries the same name, the pieces are different. The players are long gone. So are the managers and coaches. The stadium has been replaced. “You’re actually rooting for the clothes,” Jerry Seinfeld quipped. “Fans will be so in love with a player, but if he goes to a different team, they boo him. This is the same human being in a different shirt; they hate him now. Boo! Different shirt! Boo!” I think it’s a ritual. A fun but arbitrary ritual—a ceremony that we perform out of habit. We imprinted on it when we were young and impressionable, or were new to a city and looking for esprit de corps. Sure, there are moments where team loyalty does matter in our lives: it allows us to high-five acquaintances at bars and hug strangers at victory parades. It gives us a sense of solidarity. If you reflect on it, though, hating an opposing team is an accident of birth. If you had been born in New York instead of Boston, would you really hate the Yankees? For our third approach, Tim and I recruited fans of the Red Sox and Yankees. To prove their allegiance, they had to correctly name one of their team’s players from a photo—and the last year his team had won the World Series. Then we took some steps to open their minds. First, to help them recognize the complexity of their own beliefs, we asked them to list three positives and three negatives about fans of the opposing team. You saw the most common negatives earlier, but they were able to come up with some positives, too: WHAT RED SOX FANS LIKE ABOUT YANKEES FANS WHAT YANKEES FANS LIKE ABOUT RED SOX FANS Then we randomly assigned half of them to go the extra step of reflecting on the arbitrariness of their animosity: Think and write about how Yankee fans and Red Sox fans dislike each other for reasons that are fairly arbitrary. For example, if you were born into a family of fans of the rival team, you would likely also be a fan of them today. To gauge their animosity toward their opponents, we gave them a chance to decide how spicy the hot sauce sold in the rival team’s stadium should be. The backstory was that consumer product researchers ","date":"2022-09-03","objectID":"/think_again/:17:5","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"ENTERING A PARALLEL UNIVERSE Outside the lab, dismantling stereotypes and decreasing prejudice rarely happen overnight. Even if people aren’t on guard from the start, they’re quick to put their defenses up when their attitudes are challenged. Getting through to them requires more than just telling them that their views are arbitrary. A key step is getting them to do some counterfactual thinking: helping them consider what they’d believe if they were living in an alternative reality. In psychology, counterfactual thinking involves imagining how the circumstances of our lives could have unfolded differently. When we realize how easily we could have held different stereotypes, we might be more willing to update our views.* To activate counterfactual thinking, you might ask people questions like: How would your stereotypes be different if you’d been born Black, Hispanic, Asian, or Native American? What opinions would you hold if you’d been raised on a farm versus in a city, or in a culture on the other side of the world? What beliefs would you cling to if you lived in the 1700s? You’ve already learned from debate champions and expert negotiators that asking people questions can motivate them to rethink their conclusions. What’s different about these kinds of counterfactual questions is that they invite people to explore the origins of their own beliefs—and reconsider their stances toward other groups. People gain humility when they reflect on how different circumstances could have led them to different beliefs. They might conclude that some of their past convictions had been too simplistic and begin to question some of their negative views. That doubt could leave them more curious about groups they’ve stereotyped, and they might end up discovering some unexpected commonalities. Recently, I stumbled onto an opportunity to encourage some counterfactual thinking. A startup founder asked me to join an all-hands meeting to share insights on how to better understand other people’s personalities and our own. During our virtual fireside chat, she mentioned that she was an astrology fan and the company was full of them. I wondered if I could get some of them to see that they held inaccurate stereotypes about people based on the month in which they happened to be born. Here’s an excerpt of what happened: Me: You know we have no evidence whatsoever that horoscopes influence personality, right? Founder: That’s such a Capricorn thing to say. Me: I think I’m a Leo. I’d love to find out what evidence would change your mind. Founder: So my partner has been trying for as long as we’ve been dating. He’s given up. There’s nothing that can convince me otherwise. Me: Then you’re not thinking like a scientist. This is a religion for you. Founder: Yeah, well, maybe a little. Me: What if you’d been born in China instead of the U.S.? Some evidence just came out that if you’re a Virgo in China, you get discriminated against in hiring and also in dating. These poor Virgos are stereotyped as being difficult and ornery.* Founder: So in the West, Adam, that same discrimination happens to Scorpios. Although the founder started out resistant to my argument, after considering how she might hold different stereotypes if she lived in China, she recognized a familiar pattern. She’d seen an entire group of people mistreated as a result of the positions of the sun and the moon on the day they happened to enter the world. Realizing how unfair discrimination based on zodiac signs was, the founder ended up jumping in to help me build my case. As we wrapped up the conversation, I offered to do a follow-up discussion on the science of personality. More than a quarter of the company signed up to participate. Afterward, one of the participants wrote that “the biggest takeaway from this chat is the importance of ‘unlearning’ things to avoid being ignorant.” Having grasped how arbitrary their stereotypes were, people were now more open to rethinking their views. Psychologists ","date":"2022-09-03","objectID":"/think_again/:17:6","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"HOW A BLACK MUSICIAN CONFRONTS WHITE SUPREMACISTS One day, Daryl was driving his car with the chief officer of a KKK chapter, whose official title was Exalted Cyclops. Before long, the Cyclops was sharing his stereotypes of Black people. They were an inferior species, he said—they had smaller brains, which made them unintelligent, and a genetic predisposition toward violence. When Daryl pointed out that he was Black but had never shot anyone or stolen a car, the Cyclops told him his criminal gene must be latent. It hadn’t come out yet. Daryl decided to beat the Cyclops at his own game. He challenged him to name three Black serial killers. When the Cyclops couldn’t name any, Daryl rattled off a long list of well-known white serial killers and told the Cyclops that he must be one. When the Cyclops protested that he’d never killed anybody, Daryl turned his own argument against him and said that his serial-killer gene must be latent. “Well, that’s stupid,” the flustered Cyclops replied. “Well, duh!” Daryl agreed. “You’re right. What I said about you was stupid, but no more stupid than what you said about me.” The Cyclops got very quiet and changed the subject. Several months later, he told Daryl that he was still thinking about that conversation. Daryl had planted a seed of doubt and made him curious about his own beliefs. The Cyclops ended up quitting the KKK and giving his hood and his robe to Daryl. Daryl is obviously extraordinary—not only in his ability to wage a one-man war on prejudice, but also in his inclination to do so. As a general rule, it’s those with greater power who need to do more of the rethinking, both because they’re more likely to privilege their own perspectives and because their perspectives are more likely to go unquestioned. In most cases, the oppressed and marginalized have already done a great deal of contortion to fit in. Having been the target of racism since childhood, Daryl had a lifetime of legitimate reasons to harbor animosity toward white people. He was still willing to approach white supremacists with an open mind and give them the opportunity to rethink their views. But it shouldn’t have been Daryl’s responsibility to challenge white supremacists and put himself at risk. In an ideal world, the Cyclops would have taken it upon himself to educate his peers. Some other former KKK members have stepped up, working independently and with Daryl to advocate for the oppressed and reform the structures that produce oppression in the first place. As we work toward systemic change, Daryl urges us not to overlook the power of conversation. When we choose not to engage with people because of their stereotypes or prejudice, we give up on opening their minds. “We are living in space-age times, yet there are still so many of us thinking with stone-age minds,” he reflects. “Our ideology needs to catch up to our technology.” He estimates that he has helped upwards of two hundred white supremacists rethink their beliefs and leave the KKK and other neo-Nazi groups. Many of them have gone on to educate their families and friends. Daryl is quick to point out that he hasn’t directly persuaded these men to change their minds. “I didn’t convert anybody,” he says. “I gave them reason to think about their direction in life, and they thought about it, and thought, ‘I need a better path, and this is the way to go.’” Daryl doesn’t do this by preaching or prosecuting. When he begins a dialogue with white supremacists, many are initially surprised by his thoughtfulness. As they start to see him as an individual and spend more time with him, they often tap into a common identity around shared interests in topics like music. Over time, he helps them see that they joined these hate groups for reasons that weren’t their own—it was a family tradition dating back multiple generations, or someone had told them their jobs were being taken by Black men. As they realize how little they truly know about other groups, and how shallow ste","date":"2022-09-03","objectID":"/think_again/:17:7","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 7 ","date":"2022-09-03","objectID":"/think_again/:18:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Vaccine Whisperers and Mild-Mannered Interrogators ","date":"2022-09-03","objectID":"/think_again/:19:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"How the Right Kind of Listening Motivates People to Change It’s a rare person who wants to hear what he doesn’t want to hear. —attributed to dick cavett When Marie-Hélène Étienne-Rousseau went into labor, she broke down in tears. It was September 2018, and her baby wasn’t due until December. Just before midnight, Tobie arrived, weighing just two pounds. His body was so tiny that his head could fit in the palm of her hand, and Marie-Hélène was terrified that he wouldn’t survive. Tobie spent only a few seconds in her arms before he was rushed to the neonatal intensive care unit. He needed a mask to breathe and was soon taken to surgery for internal bleeding. It would be months before he was allowed to go home. While Tobie was still in the hospital, Marie-Hélène was shopping for diapers when she saw a headline about measles spreading in her province of Quebec. She hadn’t had Tobie vaccinated. It wasn’t even a question—he seemed too fragile. She hadn’t vaccinated her three other children, either; it wasn’t the norm in her community. Her friends and neighbors took it for granted that vaccines were dangerous and passed around horror stories about their side effects. Still, the fact remained: Quebec had already had two serious measles outbreaks that decade. Today in the developed world, measles is on the rise for the first time in at least half a century, and its mortality rate is around one in a thousand. In the developing world, it’s closer to one in a hundred. Estimates suggest that from 2016 to 2018, measles deaths spiked worldwide by 58 percent, with over a hundred thousand casualties. These deaths could have been prevented by the vaccine, which has saved roughly 20 million lives in the past two decades. Although epidemiologists recommend two doses of the measles vaccine and a minimum immunization rate of 95 percent, around the globe only 85 percent of people get the first dose and just 67 percent continue to the second. Many of those who skip the shot simply do not believe in the science. Government officials have tried to prosecute the problem, some warning that the unvaccinated could be fined up to a thousand dollars and sentenced to jail for up to six months. Many schools shut their doors to unvaccinated children, and one county even banned them from enclosed public places. When such measures failed to solve the problem, public officials turned to preaching. Since people held unfounded fears about vaccines, it was time to educate them with a dose of the truth. The results were often disappointing. In a pair of experiments in Germany, introducing people to the research on vaccine safety backfired: they ended up seeing vaccines as riskier. Similarly, when Americans read accounts of the dangers of measles, saw pictures of children suffering from it, or learned of an infant who nearly died from it, their interest in vaccination didn’t rise at all. And when they were informed that there was no evidence that the measles vaccine causes autism, those who already had concerns actually became less interested in vaccinating. It seemed that no logical argument or data-driven explanation could shake their conviction that vaccines were unsafe. This is a common problem in persuasion: what doesn’t sway us can make our beliefs stronger. Much like a vaccine inoculates our physical immune system against a virus, the act of resistance fortifies our psychological immune system. Refuting a point of view produces antibodies against future influence attempts. We become more certain of our opinions and less curious about alternative views. Counterarguments no longer surprise us or stump us—we have our rebuttals ready. Marie-Hélène Étienne-Rousseau had been through that journey. Visits to the doctor with her older kids followed a familiar script. The doctor extolled the benefits of vaccines, warned her about the risks of refusing them, and stuck to generic messaging instead of engaging with her particular questions. The whole experience reeked of con","date":"2022-09-03","objectID":"/think_again/:20:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"MOTIVATING THROUGH INTERVIEWING In the early 1980s, a clinical psychologist named Bill Miller was troubled by his field’s attitude toward people with addictions. It was common for therapists and counselors to accuse their substance-abusing clients of being pathological liars who were living in denial. That didn’t track with what Miller was seeing up close in his own work treating people with alcohol problems, where preaching and prosecuting typically boomeranged. “People who drink too much are usually aware of it,” Miller told me. “If you try to persuade them that they do drink too much or need to make a change, you evoke resistance, and they are less likely to change.” Instead of attacking or demeaning his clients, Miller started asking them questions and listening to their answers. Soon afterward, he published a paper on his philosophy, which found its way into the hands of Stephen Rollnick, a young nurse trainee working in addiction treatment. A few years later, the two happened to meet in Australia and realized that what they were exploring was much bigger than just a new approach to treatment. It was an entirely different way of helping people change. Together, they developed the core principles of a practice called motivational interviewing. The central premise is that we can rarely motivate someone else to change. We’re better off helping them find their own motivation to change. Let’s say you’re a student at Hogwarts, and you’re worried your uncle is a fan of Voldemort. A motivational interview might go like this: You: I’d love to better understand your feelings about He Who Must Not Be Named. Uncle: Well, he’s the most powerful wizard alive. Also, his followers promised me a fancy title. You: Interesting. Is there anything you dislike about him? Uncle: Hmm. I’m not crazy about all the murdering. You: Well, nobody’s perfect. Uncle: Yeah, but the killing is really bad. You: Sounds like you have some reservations about Voldemort. What’s stopped you from abandoning him? Uncle: I’m afraid he might direct the murdering toward me. You: That’s a reasonable fear. I’ve felt it too. I’m curious: are there any principles that matter so deeply to you that you’d be willing to take that risk? Motivational interviewing starts with an attitude of humility and curiosity. We don’t know what might motivate someone else to change, but we’re genuinely eager to find out. The goal isn’t to tell people what to do; it’s to help them break out of overconfidence cycles and see new possibilities. Our role is to hold up a mirror so they can see themselves more clearly, and then empower them to examine their beliefs and behaviors*.* That can activate a rethinking cycle, in which people approach their own views more scientifically. They develop more humility about their knowledge, doubt in their convictions, and curiosity about alternative points of view. The process of motivational interviewing involves three key techniques: Asking open-ended questions Engaging in reflective listening Affirming the person’s desire and ability to change As Marie-Hélène was getting ready to take Tobie home, the vaccine whisperer the nurses called was a neonatologist and researcher named Arnaud Gagneur. His specialty was applying the techniques of motivational interviewing to vaccination discussions. When Arnaud sat down with Marie-Hélène, he didn’t judge her for not vaccinating her children, nor did he order her to change. He was like a scientist or “a less abrasive Socrates,” as journalist Eric Boodman described him in reporting on their meeting. Arnaud told Marie-Hélène he was afraid of what might happen if Tobie got the measles, but he accepted her decision and wanted to understand it better. For over an hour, he asked her open-ended questions about how she had reached the decision not to vaccinate. He listened carefully to her answers, acknowledging that the world is full of confusing information about vaccine safety. At the end of the discussion, Arnaud reminded","date":"2022-09-03","objectID":"/think_again/:20:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"BEYOND THE CLINIC Years ago I got a call asking for help from a biotechnology startup. The CEO, Jeff, was a scientist by training; he liked to have all the necessary data before making a decision. After more than a year and a half at the helm, he still hadn’t rolled out a vision for the company, and it was in danger of failing. A trio of consultants tried to convince him to offer some direction, and he fired them all. Before the head of HR threw in the towel, she threw a Hail Mary pass and contacted an academic. It was the perfect time for a motivational interview: Jeff seemed reluctant to change, and I had no idea why. When we met, I decided to see if I could help him find his motivation to change. Here are the pivotal moments from our conversation: Me: I really enjoy being the guy who gets hired after three consultants get fired. I’d love to hear how they screwed up. Jeff: The first consultant gave me answers instead of asking questions. That was arrogant: how could he solve a problem before he’d even taken the time to understand it? The next two did a better job learning from me, but they still ended up trying to tell me how to do my job. Me: So why did you bother to bring in another outsider? Jeff: I’m looking for some fresh ideas on leadership. Me: It’s not my place to tell you how to lead. What does leadership mean to you? Jeff: Making systemic decisions, having a well-thought-out strategy. Me: Are there any leaders you admire for those qualities? Jeff: Abraham Lincoln, Martin Luther King Jr., Steve Jobs. That was a turning point. In motivational interviewing, there’s a distinction between sustain talk and change talk. Sustain talk is commentary about maintaining the status quo. Change talk is referencing a desire, ability, need, or commitment to make adjustments. When contemplating a change, many people are ambivalent—they have some reasons to consider it but also some reasons to stay the course. Miller and Rollnick suggest asking about and listening for change talk, and then posing some questions about why and how they might change. Say you have a friend who mentions a desire to stop smoking. You might respond by asking why she’s considering quitting. If she says a doctor recommended it, you might follow up by inquiring about her own motivations: what does she think of the idea? If she offers a reason why she’s determined to stop, you might ask what her first step toward quitting could be. “Change talk is a golden thread,” clinical psychologist Theresa Moyers says. “What you need to do is you need to pick that thread up and pull it.” So that’s what I did with Jeff. Me: What do you appreciate most about the leaders you named? Jeff: They all had vivid visions. They inspired people to achieve extraordinary things. Me: Interesting. If Steve Jobs were in your shoes right now, what do you think he’d do? Jeff: He’d probably get his leadership team fired up about a bold idea and create a reality distortion field to make it seem possible. Maybe I should do that, too. A few weeks later, Jeff stood up at an executive off-site to deliver his first-ever vision speech. When I heard about it, I was beaming with pride: I had conquered my inner logic bully and led him to find his own motivation. Unfortunately, the board ended up shutting down the company anyway. Jeff’s speech had fallen flat. He stumbled through notes on a napkin and didn’t stir up enthusiasm about the company’s direction. I had overlooked a key step—helping him think about how to execute the change effectively. There’s a fourth technique of motivational interviewing, which is often recommended for the end of a conversation and for transition points: summarizing. The idea is to explain your understanding of other people’s reasons for change, to check on whether you’ve missed or misrepresented anything, and to inquire about their plans and possible next steps. The objective is not to be a leader or a follower, but a guide. Miller and Rollnick liken it to hiring a tour g","date":"2022-09-03","objectID":"/think_again/:20:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE ART OF INFLUENTIAL LISTENING Betty Bigombe had already hiked eight miles through the jungle, and there was still no sign of life. She was no stranger to a long walk: growing up in northern Uganda, she walked four miles each way to school. She subsisted on one meal a day in a communal homestead where her uncle had eight wives. Now she had made it all the way to the Ugandan Parliament, and she was undertaking a challenge that none of her colleagues would brave: trying to make peace with a warlord. Joseph Kony was the leader of the Lord’s Resistance Army. He and his rebel group would eventually be held responsible for murdering over a hundred thousand people, abducting over thirty thousand children, and displacing over two million Ugandans. In the early 1990s, Betty convinced the Ugandan president to send her in to see if she could stop the violence. When Betty finally made contact with the rebels after months of effort, they were insulted at the prospect of negotiating with a woman. Yet Betty negotiated her way into getting permission to meet Kony himself. Soon he was referring to her as Mummy, and he even agreed to leave the jungle to start peace talks. Although the peace effort didn’t succeed, opening Kony’s mind to conversation was a remarkable accomplishment in itself.* For her efforts to end the violence, Betty was named Uganda’s Woman of the Year. When I spoke to her recently, I asked how she had succeeded in getting through to Kony and his people. The key, she explained, was not persuading or even coaxing, but listening. Listening well is more than a matter of talking less. It’s a set of skills in asking and responding. It starts with showing more interest in other people’s interests rather than trying to judge their status or prove our own. We can all get better at asking “truly curious questions that don’t have the hidden agenda of fixing, saving, advising, convincing or correcting,” journalist Kate Murphy writes, and helping to “facilitate the clear expression of another person’s thoughts.”* When we’re trying to get people to change, that can be a difficult task. Even if we have the best intentions, we can easily slip into the mode of a preacher perched on a pulpit, a prosecutor making a closing argument, or a politician giving a stump speech. We’re all vulnerable to the “righting reflex,” as Miller and Rollnick describe it—the desire to fix problems and offer answers. A skilled motivational interviewer resists the righting reflex—although people want a doctor to fix their broken bones, when it comes to the problems in their heads, they often want sympathy rather than solutions. That’s what Betty Bigombe set out to provide in Uganda. She started traveling through rural areas to visit camps for internally displaced people. She figured some might have relatives in Joseph Kony’s army and might know something of his whereabouts. Although she hadn’t been trained in motivational interviewing, she intuitively understood the philosophy. At each camp, she announced to people that she wasn’t there to lecture them, but to listen to them. Her curiosity and confident humility caught the Ugandans by surprise. Other peacemakers had come in ordering them to stop fighting. They had preached about their own plans for conflict resolution and prosecuted the past efforts that failed. Now Betty, a politician by profession, wasn’t telling them what to do. She just sat patiently for hours in front of a bonfire, taking notes and chiming in from time to time to ask questions. “If you want to call me names, feel free to do so,” she said. “If you want me to leave, I will.” To demonstrate her commitment to peace, Betty stayed in the camps even though they lacked sufficient food and proper sanitation. She invited people to air their grievances and suggest remedial measures to be taken. They told her that it was rare and refreshing for an outsider to give them the opportunity to share their views. She empowered them to generate their own solutio","date":"2022-09-03","objectID":"/think_again/:20:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 8 ","date":"2022-09-03","objectID":"/think_again/:21:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Charged Conversations ","date":"2022-09-03","objectID":"/think_again/:22:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Depolarizing Our Divided Discussions When conflict is cliché, complexity is breaking news. —amanda ripley Eager to have a jaw-clenching, emotionally fraught argument about abortion? How about immigration, the death penalty, or climate change? If you think you can handle it, head for the second floor of a brick building on the Columbia University campus in New York. It’s the home of the Difficult Conversations Lab. If you’re brave enough to visit, you’ll be matched up with a stranger who strongly disagrees with your views on a controversial topic. You’ll be given just twenty minutes to discuss the issue, and then you’ll both have to decide whether you’ve aligned enough to write and sign a joint statement on your shared views around abortion laws. If you’re able to do so—no small feat—your statement will be posted on a public forum. For two decades, the psychologist who runs the lab, Peter T. Coleman, has been bringing people together to talk about polarizing issues. His mission is to reverse-engineer the successful conversations and then experiment with recipes to make more of them. To put you in the right mindset before you begin your conversation about abortion, Peter gives you and the stranger a news article about another divisive issue: gun control. What you don’t know is that there are different versions of the gun control article, and which one you read is going to have a major impact on whether you land on the same page about abortion. If the gun control article covers both sides of the issue, making a balanced case for both gun rights and gun legislation, you and your adversary have a decent chance at reaching consensus on abortion. In one of Peter’s experiments, after reading a “both-sides” article, 46 percent of pairs were able to find enough common ground to draft and sign a statement together. That’s a remarkable result. But Peter went on to do something far more impressive. He randomly assigned some pairs to read another version of the same article, which led 100 percent of them to generate and sign a joint statement about abortion laws. That version of the article featured the same information but presented it differently. Instead of describing the issue as a black-and-white disagreement between two sides, the article framed the debate as a complex problem with many shades of gray, representing a number of different viewpoints. At the turn of the last century, the great hope for the internet was that it would expose us to different views. But as the web welcomed a few billion fresh voices and vantage points into the conversation, it also became a weapon of misinformation and disinformation. By the 2016 elections, as the problem of political polarization became more extreme and more visible, the solution seemed obvious to me. We needed to burst filter bubbles in our news feeds and shatter echo chambers in our networks. If we could just show people the other side of an issue, they would open their minds and become more informed. Peter’s research challenges that assumption. We now know that where complicated issues are concerned, seeing the opinions of the other side is not enough. Social media platforms have exposed us to them, but they haven’t changed our minds. Knowing another side exists isn’t sufficient to leave preachers doubting whether they’re on the right side of morality, prosecutors questioning whether they’re on the right side of the case, or politicians wondering whether they’re on the right side of history. Hearing an opposing opinion doesn’t necessarily motivate you to rethink your own stance; it makes it easier for you to stick to your guns (or your gun bans). Presenting two extremes isn’t the solution; it’s part of the polarization problem. Psychologists have a name for this: binary bias. It’s a basic human tendency to seek clarity and closure by simplifying a complex continuum into two categories. To paraphrase the humorist Robert Benchley, there are two kinds of people: those who divide the world i","date":"2022-09-03","objectID":"/think_again/:23:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"SOME INCONVENIENT TRUTHS In 2006, Al Gore starred in a blockbuster film on climate change, An Inconvenient Truth. It won the Academy Award for Best Documentary and spawned a wave of activism, motivating businesses to go green and governments to pass legislation and sign landmark agreements to protect the planet. History teaches us that it sometimes takes a combination of preaching, prosecuting, and politicking to fuel that kind of dramatic swing. Yet by 2018, only 59 percent of Americans saw climate change as a major threat—and 16 percent believed it wasn’t a threat at all. Across many countries in Western Europe and Southeast Asia, higher percentages of the populations had opened their minds to the evidence that climate change is a dire problem. In the past decade in the United States, beliefs about climate change have hardly budged. This thorny issue is a natural place to explore how we can bring more complexity into our conversations. Fundamentally, that involves drawing attention to the nuances that often get overlooked. It starts with seeking and spotlighting shades of gray. A fundamental lesson of desirability bias is that our beliefs are shaped by our motivations. What we believe depends on what we want to believe. Emotionally, it can be unsettling for anyone to admit that all life as we know it might be in danger, but Americans have some additional reasons to be dubious about climate change. Politically, climate change has been branded in the United States as a liberal issue; in some conservative circles, merely acknowledging the fact that it might exist puts people on a fast track to exile. There’s evidence that higher levels of education predict heightened concern about climate change among Democrats but dampened concern among Republicans. Economically, we remain confident that America will be more resilient in response to a changing climate than most of the world, and we’re reluctant to sacrifice our current ways of achieving prosperity. These deep-seated beliefs are hard to change. As a psychologist, I want to zoom in on another factor. It’s one we can all control: the way we communicate about climate change. Many people believe that preaching with passion and conviction is necessary for persuasion. A clear example is Al Gore. When he narrowly lost the U.S. presidential election in 2000, one of the knocks against him was his energy—or lack thereof. People called him dry. Boring. Robotic. Fast-forward a few years: his film was riveting and his own platform skills had evolved dramatically. In 2016, when I watched Gore speak in the red circle at TED, his language was vivid, his voice pulsated with emotion, and his passion literally dripped off him in the form of sweat. If a robot was ever controlling his brain, it short-circuited and left the human in charge. “Some still doubt that we have the will to act,” he boomed, “but I say the will to act is itself a renewable resource.” The audience erupted in a standing ovation, and afterward he was called the Elvis of TED. If it’s not his communication style that’s failing to reach people, what is? At TED, Gore was preaching to the choir: his audience was heavily progressive. For audiences with more varied beliefs, his language hasn’t always resonated. In An Inconvenient Truth, Gore contrasted the “truth” with claims made by “so-called skeptics.” In a 2010 op-ed, he contrasted scientists with “climate deniers.” This is binary bias in action. It presumes that the world is divided into two sides: believers and nonbelievers. Only one side can be right, because there is only one truth. I don’t blame Al Gore for taking that position; he was presenting rigorous data and representing the consensus of the scientific community. Because he was a recovering politician, seeing two sides to an issue must have been second nature. But when the only available options are black and white, it’s natural to slip into a mentality of us versus them and to focus on the sides over the science. For t","date":"2022-09-03","objectID":"/think_again/:23:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"SOME CAVEATS AND CONTINGENCIES If you want to get better at conveying complexity, it’s worth taking a close look at how scientists communicate. One key step is to include caveats. It’s rare that a single study or even a series of studies is conclusive. Researchers typically feature multiple paragraphs about the limitations of each study in their articles. We see them less as holes in our work and more as portholes to future discoveries. When we share the findings with nonscientists, though, we sometimes gloss over these caveats. That’s a mistake, according to recent research. In a series of experiments, psychologists demonstrated that when news reports about science included caveats, they succeeded in capturing readers’ interest and keeping their minds open. Take a study suggesting that a poor diet accelerates aging. Readers were just as engaged in the story—but more flexible in their beliefs—when it mentioned that scientists remained hesitant to draw strong causal conclusions given the number of factors that can affect aging. It even helped just to note that scientists believed more work needed to be done in this area. We can also convey complexity by highlighting contingencies. Every empirical finding raises unanswered questions about when and where results will be replicated, nullified, or reversed. Contingencies are all the places and populations where an effect may change. Consider diversity: although headlines often say “Diversity is good,” the evidence is full of contingencies. Although diversity of background and thought has the potential to help groups think more broadly and process information more deeply, that potential is realized in some situations but not others. New research reveals that people are more likely to promote diversity and inclusion when the message is more nuanced (and more accurate): “Diversity is good, but it isn’t easy.”* Acknowledging complexity doesn’t make speakers and writers less convincing; it makes them more credible. It doesn’t lose viewers and readers; it maintains their engagement while stoking their curiosity. In social science, rather than cherry-picking information to fit our existing narratives, we’re trained to ask whether we should rethink and revise those narratives. When we find evidence that doesn’t fit neatly into our belief systems, we’re expected to share it anyway.* In some of my past writing for the public, though, I regret not having done enough to emphasize areas where evidence was incomplete or conflicting. I sometimes shied away from discussing mixed results because I didn’t want to leave readers confused. Research suggests that many writers fall into the same trap, caught up in trying to “maintain a consistent narrative rather than an accurate record.” A fascinating example is the divide around emotional intelligence. On one extreme is Daniel Goleman, who popularized the concept. He preaches that emotional intelligence matters more for performance than cognitive ability (IQ) and accounts for “nearly 90 percent” of success in leadership jobs. At the other extreme is Jordan Peterson, writing that “There is NO SUCH THING AS EQ” and prosecuting emotional intelligence as “a fraudulent concept, a fad, a convenient band-wagon, a corporate marketing scheme.” Both men hold doctorates in psychology, but neither seems particularly interested in creating an accurate record. If Peterson had bothered to read the comprehensive meta-analyses of studies spanning nearly two hundred jobs, he’d have discovered that—contrary to his claims—emotional intelligence is real and it does matter. Emotional intelligence tests predict performance even after controlling for IQ and personality. If Goleman hadn’t ignored those same data, he’d have learned that if you want to predict performance across jobs, IQ is more than twice as important as emotional intelligence (which accounts for only 3 to 8 percent of performance). I think they’re both missing the point. Instead of arguing about whether emotio","date":"2022-09-03","objectID":"/think_again/:23:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"MIXED FEELINGS In polarized discussions, a common piece of advice is to take the other side’s perspective. In theory, putting ourselves in another person’s shoes enables us to walk in lockstep with them. In practice, though, it’s not that simple. In a pair of experiments, randomly assigning people to reflect on the intentions and interests of their political opposites made them less receptive to rethinking their own attitudes on health care and universal basic income. Across twenty-five experiments, imagining other people’s perspectives failed to elicit more accurate insights—and occasionally made participants more confident in their own inaccurate judgments. Perspective-taking consistently fails because we’re terrible mind readers. We’re just guessing. If we don’t understand someone, we can’t have a eureka moment by imagining his perspective. Polls show that Democrats underestimate the number of Republicans who recognize the prevalence of racism and sexism—and Republicans underestimate the number of Democrats who are proud to be Americans and oppose open borders. The greater the distance between us and an adversary, the more likely we are to oversimplify their actual motives and invent explanations that stray far from their reality. What works is not perspective-taking but perspective-seeking: actually talking to people to gain insight into the nuances of their views. That’s what good scientists do: instead of drawing conclusions about people based on minimal clues, they test their hypotheses by striking up conversations. For a long time, I believed that the best way to make those conversations less polarizing was to leave emotions out of them. If only we could keep our feelings off the table, we’d all be more open to rethinking. Then I read evidence that complicated my thinking. It turns out that even if we disagree strongly with someone on a social issue, when we discover that she cares deeply about the issue, we trust her more. We might still dislike her, but we see her passion for a principle as a sign of integrity. We reject the belief but grow to respect the person behind it. It can help to make that respect explicit at the start of a conversation. In one experiment, if an ideological opponent merely began by acknowledging that “I have a lot of respect for people like you who stand by their principles,” people were less likely to see her as an adversary—and showed her more generosity. When Peter Coleman brings people together in his Difficult Conversations Lab, he plays them the recording of their discussions afterward. What he wants to learn is how they were feeling, moment by moment, as they listen to themselves. After studying over five hundred of these conversations, he found that the unproductive ones feature a more limited set of both positive and negative emotions, as illustrated below in the image on the left. People get trapped in emotional simplicity, with one or two dominant feelings. As you can see with the duo on the right, the productive conversations cover a much more varied spectrum of emotions. They’re not less emotional—they’re more emotionally complex. At one point, people might be angry about the other person’s views, but by the next minute they’re curious to learn more. Soon they could be shifting into anxiety and then excitement about considering a new perspective. Sometimes they even stumble into the joy of being wrong. In a productive conversation, people treat their feelings as a rough draft. Like art, emotions are works in progress. It rarely serves us well to frame our first sketch. As we gain perspective, we revise what we feel. Sometimes we even start over from scratch. What stands in the way of rethinking isn’t the expression of emotion; it’s a restricted range of emotion. So how do we infuse our charged conversations with greater emotional variety—and thereby greater potential for mutual understanding and rethinking? It helps to remember that we can fall victim to binary bias with emotions","date":"2022-09-03","objectID":"/think_again/:23:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 9 ","date":"2022-09-03","objectID":"/think_again/:24:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Rewriting the Textbook ","date":"2022-09-03","objectID":"/think_again/:25:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Teaching Students to Question Knowledge No schooling was allowed to interfere with my education. —grant allen Adecade ago, if you had told Erin McCarthy she would become a teacher, she would have laughed. When she graduated from college, the last thing she wanted to do was teach. She was fascinated by history but bored by her social studies classes. Searching for a way to breathe life into overlooked objects and forgotten events, Erin started her career working in museums. Before long, she found herself writing a resource manual for teachers, leading school tours, and engaging students in interactive programs. She realized that the enthusiasm she saw on field trips was missing in too many classrooms, and she decided to do something about it. For the past eight years, Erin has taught social studies in the Milwaukee area. Her mission is to cultivate curiosity about the past, but also to motivate students to update their knowledge in the present. In 2020, she was named Wisconsin’s Teacher of the Year. One day, an eighth grader complained that the reading assignment from a history textbook was inaccurate. If you’re a teacher, that kind of criticism could be a nightmare. Using an outdated textbook would be a sign that you don’t know your material, and it would be embarrassing if your students noticed the error before you did. But Erin had assigned that particular reading intentionally. She collects old history books because she enjoys seeing how the stories we tell change over time, and she decided to give her students part of a textbook from 1940. Some of them just accepted the information it presented at face value. Through years of education, they had come to take it for granted that textbooks told the truth. Others were shocked by errors and omissions. It was ingrained in their minds that their readings were filled with incontrovertible facts. The lesson led them to start thinking like scientists and questioning what they were learning: whose story was included, whose was excluded, and what were they missing if only one or two perspectives were shared? After opening her students’ eyes to the fact that knowledge can evolve, Erin’s next step was to show them that it’s always evolving. To set up a unit on expansion in the West, she created her own textbook section describing what it’s like to be a middle-school student today. All the protagonists were women and girls, and all the generic pronouns were female. In the first year she introduced the material, a student raised his hand to point out that the boys were missing. “But there’s one boy,” Erin replied. “Boys were around. They just weren’t doing anything important.” It was an aha moment for the student: he suddenly realized what it was like for an entire group to be marginalized for hundreds of years. My favorite assignment of Erin’s is her final one. As a passionate champion of inquiry-based learning, she sends her eighth graders off to do self-directed research in which they inspect, investigate, interrogate, and interpret. Their active learning culminates in a group project: they pick a chapter from their textbook, choosing a time period that interests them and a theme in history that they see as underrepresented. Then they go off to rewrite it. One group took on the civil rights chapter for failing to cover the original March on Washington, which was called off at the last minute in the early 1940s but inspired Martin Luther King Jr.’s historic march two decades later. Other groups revised the chapter on World War II to include the infantry regiments of Hispanic soldiers and second-generation Japanese soldiers who fought for the U.S. Army. “It’s a huge light-bulb moment,” Erin told me. Even if you’re not a teacher by profession, you probably have roles in which you spend time educating others—whether as a parent, a mentor, a friend, or a colleague. In fact, every time we try to help someone think again, we’re doing a kind of education. Whether we do our instruction in a cl","date":"2022-09-03","objectID":"/think_again/:26:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"LEARNING, INTERRUPTED Looking back on my own early education, one of my biggest disappointments is that I never got to fully experience the biggest upheavals in science. Long before it ever occurred to me to be curious about the cosmos, my teachers started demystifying it in kindergarten. I often wonder how I would have felt if I was a teenager when I first learned that we don’t live on a static, flat disc, but on a spinning, moving sphere. I hope I would have been stunned, and that disbelief would have quickly given way to curiosity and eventually the awe of discovery and the joy of being wrong. I also suspect it would have been a life-changing lesson in confident humility. If I could be that mistaken about what was under my own two feet, how many other so-called truths were actually question marks? Sure, I knew that many earlier generations of humans had gotten it wrong, but there’s a huge difference between learning about other people’s false beliefs and actually learning to unbelieve things ourselves. I realize this thought experiment is wildly impractical. It’s hard enough to keep kids in the dark about Santa Claus or the Tooth Fairy. Even if we could pull off such a delay, there’s a risk that some students would seize and freeze on what they learned early on. They could become trapped in an overconfidence cycle where pride in false knowledge fuels conviction, and confirmation and desirability biases lead to validation. Before you know it, we might have a whole nation of flat-earthers. Evidence shows that if false scientific beliefs aren’t addressed in elementary school, they become harder to change later. “Learning counterintuitive scientific ideas [is] akin to becoming a fluent speaker of a second language,” psychologist Deborah Kelemen writes. It’s “a task that becomes increasingly difficult the longer it is delayed, and one that is almost never achieved with only piecemeal instruction and infrequent practice.” That’s what kids really need: frequent practice at unlearning, especially when it comes to the mechanisms of how cause and effect work. In the field of history education, there’s a growing movement to ask questions that don’t have a single right answer. In a curriculum developed at Stanford, high school students are encouraged to critically examine what really caused the Spanish-American War, whether the New Deal was a success, and why the Montgomery bus boycott was a watershed moment. Some teachers even send students out to interview people with whom they disagree. The focus is less on being right, and more on building the skills to consider different views and argue productively about them. That doesn’t mean all interpretations are accepted as valid. When the son of a Holocaust survivor came to her class, Erin McCarthy told her students that some people denied the existence of the Holocaust, and taught them to examine the evidence and reject those false claims. This is part of a broader movement to teach kids to think like fact-checkers: the guidelines include (1) “interrogate information instead of simply consuming it,” (2) “reject rank and popularity as a proxy for reliability,” and (3) “understand that the sender of information is often not its source.” These principles are valuable beyond the classroom. At our family dinner table, we sometimes hold myth-busting discussions. My wife and I have shared how we learned in school that Pluto was a planet (not true anymore) and Columbus discovered America (never true). Our kids have taught us that King Tut probably didn’t die in a chariot accident and gleefully explained that when sloths do their version of a fart, the gas comes not from their behinds but from their mouths. Rethinking needs to become a regular habit. Unfortunately, traditional methods of education don’t always allow students to form that habit. ","date":"2022-09-03","objectID":"/think_again/:26:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE DUMBSTRUCK EFFECT It’s week twelve of physics class, and you get to attend a couple of sessions with a new, highly rated instructor to learn about static equilibrium and fluids. The first session is on statics; it’s a lecture. The second is on fluids, and it’s an active-learning session. One of your roommates has a different, equally popular instructor who does the opposite—using active learning for statics and lecturing on fluids. In both cases the content and the handouts are identical; the only difference is the delivery method. During the lecture the instructor presents slides, gives explanations, does demonstrations, and solves sample problems, and you take notes on the handouts. In the active-learning session, instead of doing the example problems himself, the instructor sends the class off to figure them out in small groups, wandering around to ask questions and offer tips before walking the class through the solution. At the end, you fill out a survey. In this experiment the topic doesn’t matter: the teaching method is what shapes your experience. I expected active learning to win the day, but the data suggest that you and your roommate will both enjoy the subject more when it’s delivered by lecture. You’ll also rate the instructor who lectures as more effective—and you’ll be more likely to say you wish all your physics courses were taught that way. Upon reflection, the appeal of dynamic lectures shouldn’t be surprising. For generations, people have admired the rhetorical eloquence of poets like Maya Angelou, politicians like John F. Kennedy Jr. and Ronald Reagan, preachers like Martin Luther King Jr., and teachers like Richard Feynman. Today we live in a golden age of spellbinding speaking, where great orators engage and educate from platforms with unprecedented reach. Creatives used to share their methods in small communities; now they can accumulate enough YouTube and Instagram subscribers to populate a small country. Pastors once gave sermons to hundreds at church; now they can reach hundreds of thousands over the internet in megachurches. Professors used to teach small enough classes that they could spend individual time with each student; now their lessons can be broadcast to millions through online courses. It’s clear that these lectures are entertaining and informative. The question is whether they’re the ideal method of teaching. In the physics experiment, the students took tests to gauge how much they had learned about statics and fluids. Despite enjoying the lectures more, they actually gained more knowledge and skill from the active-learning session. It required more mental effort, which made it less fun but led to deeper understanding. For a long time, I believed that we learn more when we’re having fun. This research convinced me I was wrong. It also reminded me of my favorite physics teacher, who got stellar reviews for letting us play Ping-Pong in class, but didn’t quite make the coefficient of friction stick. Active learning has impact far beyond physics. A meta-analysis compared the effects of lecturing and active learning on students’ mastery of the material, cumulating 225 studies with over 46,000 undergraduates in science, technology, engineering, and math (STEM). Active-learning methods included group problem solving, worksheets, and tutorials. On average, students scored half a letter grade worse under traditional lecturing than through active learning—and students were 1.55 times more likely to fail in classes with traditional lecturing. The researchers estimate that if the students who failed in lecture courses had participated in active learning, more than $3.5 million in tuition could have been saved. It’s not hard to see why a boring lecture would fail, but even captivating lectures can fall short for a less obvious, more concerning reason. Lectures aren’t designed to accommodate dialogue or disagreement; they turn students into passive receivers of information rather than active thinker","date":"2022-09-03","objectID":"/think_again/:26:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE UNBEARABLE LIGHTNESS OF REPEATING There’s only one class I regret missing in college. It was taught by a philosopher named Robert Nozick. One of his ideas became famous thanks to the movie The Matrix: in the 1970s, Nozick introduced a thought experiment about whether people would choose to enter an “experience machine” that could provide infinite pleasure but remove them from real life.* In his classroom, Nozick created his own version of an experience machine: he insisted on teaching a new class every year. “I do my thinking through the courses I give,” he said. Nozick taught one course on truth; another on philosophy and neuroscience; a third on Socrates, Buddha, and Jesus; a fourth on thinking about thinking; and a fifth on the Russian Revolution. In four decades of teaching, he taught only one class a second time: it was on the good life. “Presenting a completely polished and worked-out view doesn’t give students a feel for what it’s like to do original work in philosophy and to see it happen, to catch on to doing it,” he explained. Sadly, before I could take one of his courses, he died of cancer. What I found so inspiring about Nozick’s approach was that he wasn’t content for students to learn from him. He wanted them to learn with him. Every time he tackled a new topic, he would have the opportunity to rethink his existing views on it. He was a remarkable role model for changing up our familiar methods of teaching—and learning. When I started teaching, I wanted to adopt some of his principles. I wasn’t prepared to inflict an entire semester of half-baked ideas on my students, so I set a benchmark: every year I would aim to throw out 20 percent of my class and replace it with new material. If I was doing new thinking every year, we could all start rethinking together. With the other 80 percent of the material, though, I found myself failing. I was teaching a semester-long class on organizational behavior for juniors and seniors. When I introduced evidence, I wasn’t giving them the space to rethink it. After years of wrestling with this problem, it dawned on me that I could create a new assignment to teach rethinking. I assigned students to work in small groups to record their own mini-podcasts or mini–TED talks. Their charge was to question a popular practice, to champion an idea that went against the grain of conventional wisdom, or to challenge principles covered in class. As they started working on the project, I noticed a surprising pattern. The students who struggled the most were the straight-A students—the perfectionists. It turns out that although perfectionists are more likely than their peers to ace school, they don’t perform any better than their colleagues at work. This tracks with evidence that, across a wide range of industries, grades are not a strong predictor of job performance. Achieving excellence in school often requires mastering old ways of thinking. Building an influential career demands new ways of thinking. In a classic study of highly accomplished architects, the most creative ones graduated with a B average. Their straight-A counterparts were so determined to be right that they often failed to take the risk of rethinking the orthodoxy. A similar pattern emerged in a study of students who graduated at the top of their class. “Valedictorians aren’t likely to be the future’s visionaries,” education researcher Karen Arnold explains. “They typically settle into the system instead of shaking it up.” That’s what I saw with my straight-A students: they were terrified of being wrong. To give them a strong incentive to take some risks, I made the assignment worth 20 percent of their final grade. I had changed the rules: now they were being rewarded for rethinking instead of regurgitating. I wasn’t sure if that incentive would work until I reviewed the work of a trio of straight-A students. They gave their mini–TED talk about the problems with TED talks, pointing out the risks of reinforcing short atte","date":"2022-09-03","objectID":"/think_again/:26:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"JACK OF ROUGH DRAFTS, MASTER OF CRAFTS When I asked a handful of education pioneers to name the best teacher of rethinking they’ve ever encountered, I kept hearing the same name: Ron Berger. If you invited Ron over for dinner, he’s the kind of person who would notice that one of your chairs was broken, ask if you had some tools handy, and fix it on the spot. For most of his career, Ron was a public-elementary-school teacher in rural Massachusetts. His nurse, his plumber, and his local firefighters were all former students. During the summers and on weekends, he worked as a carpenter. Ron has devoted his life to teaching students an ethic of excellence. Mastering a craft, in his experience, is about constantly revising our thinking. Hands-on craftsmanship is the foundation for his classroom philosophy. Ron wanted his students to experience the joy of discovery, so he didn’t start by teaching them established knowledge. He began the school year by presenting them with “grapples”—problems to work through in phases. The approach was think-pair-share: the kids started individually, updated their ideas in small groups, and then presented their thoughts to the rest of the class, arriving at solutions together. Instead of introducing existing taxonomies of animals, for example, Ron had them develop their own categories first. Some students classified animals by whether they walked on land, swam in water, or flew through the air; others arranged them according to color, size, or diet. The lesson was that scientists always have many options, and their frameworks are useful in some ways but arbitrary in others. When students confront complex problems, they often feel confused. A teacher’s natural impulse is to rescue them as quickly as possible so they don’t feel lost or incompetent. Yet psychologists find that one of the hallmarks of an open mind is responding to confusion with curiosity and interest. One student put it eloquently: “I need time for my confusion.” Confusion can be a cue that there’s new territory to be explored or a fresh puzzle to be solved. Ron wasn’t content to deliver lessons that erased confusion. He wanted students to embrace confusion. His vision was for them to become leaders of their own learning, much like they would in “do it yourself” (DIY) craft projects. He started encouraging students to think like young scientists: they would identify problems, develop hypotheses, and design their own experiments to test them. His sixth graders went around the community to test local homes for radon gas. His third graders created their own maps of amphibian habitats. His first graders got their own group of snails to take care of, and went on to test which of over 140 foods they liked—and whether they preferred hot or cold, dark or light, and wet or dry environments. For architecture and engineering lessons, Ron had his students create blueprints for a house. When he required them to do at least four different drafts, other teachers warned him that younger students would become discouraged. Ron disagreed—he had already tested the concept with kindergarteners and first graders in art. Rather than asking them to simply draw a house, he announced, “We’ll be doing four different versions of a drawing of a house.” Some students didn’t stop there; many wound up deciding to do eight or ten drafts. The students had a support network of classmates cheering them on in their efforts. “Quality means rethinking, reworking, and polishing,” Ron reflects. “They need to feel they will be celebrated, not ridiculed, for going back to the drawing board. . . . They soon began complaining if I didn’t allow them to do more than one version.” Ron wanted to teach his students to revise their thinking based on input from others, so he turned the classroom into a challenge network. Every week—and sometimes every day—the entire class would do a critique session. One format was a gallery critique: Ron put everyone’s work on display, sent students aro","date":"2022-09-03","objectID":"/think_again/:26:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 10 ","date":"2022-09-03","objectID":"/think_again/:27:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"That’s Not the Way We’ve Always Done It ","date":"2022-09-03","objectID":"/think_again/:28:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Building Cultures of Learning at Work If only it weren’t for the people . . . earth would be an engineer’s paradise. —kurt vonnegut As an avid scuba diver, Luca Parmitano was familiar with the risks of drowning. He just didn’t realize it could happen in outer space. Luca had just become the youngest astronaut ever to take a long trip to the International Space Station. In July 2013, the thirty-six-year-old Italian astronaut completed his first spacewalk, spending six hours running experiments, moving equipment, and setting up power and data cables. Now, a week later, Luca and another astronaut, Chris Cassidy, were heading out for a second walk to continue their work and do some maintenance. As they prepared to leave the airlock, they could see the Earth 250 miles below. After forty-four minutes in space, Luca felt something strange: the back of his head seemed to be wet. He wasn’t sure where the water was coming from. It wasn’t just a nuisance; it could cut off communication by shorting out his microphone or earphones. He reported the problem to Mission Control in Houston, and Chris asked if he was sweating. “I am sweating,” Luca said, “but it feels like a lot of water. It’s not going anywhere, it’s just in my Snoopy cap. Just FYI.” He went back to work. The officer in charge of spacewalks, Karina Eversley, knew something was wrong. That’s not normal, she thought, and quickly recruited a team of experts to compile questions for Luca. Was the amount of liquid increasing? Luca couldn’t tell. Was he sure it was water? When he stuck out his tongue to capture a few of the drops that were floating in his helmet, the taste was metallic. Mission Control made the call to terminate the spacewalk early. Luca and Chris had to split up to follow their tethers, which were routed in opposite directions. To get around an antenna, Luca flipped over. Suddenly, he couldn’t see clearly or breathe through his nose—globs of water were covering his eyes and filling his nostrils. The water was continuing to accumulate, and if it reached his mouth he could drown. His only hope was to navigate quickly back to the airlock. As the sun set, Luca was surrounded by darkness, with only a small headlight to guide him. Then his comms went down, too—he couldn’t hear himself or anyone else speak. Luca managed to find his way back to the outer hatch of the airlock, using his memory and the tension in his tether. He was still in grave danger: before he could remove his helmet, he would have to wait for Chris to close the hatch and repressurize the airlock. For several agonizing minutes of silence, it was unclear whether he would survive. When it was finally safe to remove his helmet, a quart and a half of water was in it, but Luca was alive. Months later, the incident would be called the “scariest wardrobe malfunction in NASA history.” The technical updates followed swiftly. The spacesuit engineers traced the leak to a fan/pump/separator, which they replaced moving forward. They also added a breathing tube that works like a snorkel and a pad to absorb water inside the helmet. Yet the biggest error wasn’t technical—it was human. When Luca had returned from his first spacewalk a week earlier, he had noticed some droplets of water in his helmet. He and Chris assumed they were the result of a leak in the bag that provided drinking water in his suit, and the crew in Houston agreed. Just to be safe, they replaced the bag, but that was the end of the discussion. The space station chief engineer, Chris Hansen, led the eventual investigation into what had gone wrong with Luca’s suit. “The occurrence of minor amounts of water in the helmet was normalized,” Chris told me. In the space station community, the “perception was that drink bags leak, which led to an acceptance that it was a likely explanation without digging deeper into it.” Luca’s scare wasn’t the first time that NASA’s failure at rethinking had proven disastrous. In 1986, the space shuttle Challenger exploded af","date":"2022-09-03","objectID":"/think_again/:29:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"I ERR, THEREFORE I LEARN Years ago, an engineer turned management professor named Amy Edmondson became interested in preventing medical errors. She went into a hospital and surveyed its staff about the degree of psychological safety they experienced in their teams—could they take risks without the fear of being punished? Then she collected data on the number of medical errors each team made, tracking serious outcomes like potentially fatal doses of the wrong medication. She was surprised to find that the more psychological safety a team felt, the higher its error rates. It appeared that psychological safety could breed complacency. When trust runs deep in a team, people might not feel the need to question their colleagues or double-check their own work. But Edmondson soon recognized a major limitation of the data: the errors were all self-reported. To get an unbiased measure of mistakes, she sent a covert observer into the units. When she analyzed those data, the results flipped: psychologically safe teams reported more errors, but they actually made fewer errors. By freely admitting their mistakes, they were then able to learn what had caused them and eliminate them moving forward. In psychologically unsafe teams, people hid their mishaps to avoid penalties, which made it difficult for anyone to diagnose the root causes and prevent future problems. They kept repeating the same mistakes. Since then, research on psychological safety has flourished. When I was involved in a study at Google to identify the factors that distinguish teams with high performance and well-being, the most important differentiator wasn’t who was on the team or even how meaningful their work was. What mattered most was psychological safety. Over the past few years, psychological safety has become a buzzword in many workplaces. Although leaders might understand its significance, they often misunderstand exactly what it is and how to create it. Edmondson is quick to point out that psychological safety is not a matter of relaxing standards, making people comfortable, being nice and agreeable, or giving unconditional praise. It’s fostering a climate of respect, trust, and openness in which people can raise concerns and suggestions without fear of reprisal. It’s the foundation of a learning culture. In performance cultures, the emphasis on results often undermines psychological safety. When we see people get punished for failures and mistakes, we become worried about proving our competence and protecting our careers. We learn to engage in self-limiting behavior, biting our tongues rather than voicing questions and concerns. Sometimes that’s due to power distance: we’re afraid of challenging the big boss at the top. The pressure to conform to authority is real, and those who dare to deviate run the risk of backlash. In performance cultures, we also censor ourselves in the presence of experts who seem to know all the answers—especially if we lack confidence in our own expertise. A lack of psychological safety was a persistent problem at NASA. Before the Challenger launch, some engineers did raise red flags but were silenced by managers; others were ignored and ended up silencing themselves. After the Columbia launch, an engineer asked for clearer photographs to inspect the damage to the wing, but managers didn’t supply them. In a critical meeting to evaluate the condition of the shuttle after takeoff, the engineer didn’t speak up. About a month before that Columbia launch, Ellen Ochoa became the deputy director of flight crew operations. In 1993, Ellen had made history by becoming the first Latina in space. Now, the first flight she supported in a management role had ended in tragedy. After breaking the news to the space station crew and consoling the family members of the fallen astronauts, she was determined to figure out how she could personally help to prevent this kind of disaster from ever happening again. Ellen recognized that at NASA, the performance cu","date":"2022-09-03","objectID":"/think_again/:29:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"SAFE AT HOME GATES When I first arrived at the Gates Foundation, people were whispering about the annual strategy reviews. It’s the time when program teams across the foundation meet with the cochairs—Bill and Melinda Gates—and the CEO to give progress reports on execution and collect feedback. Although the foundation employs some of the world’s leading experts in areas ranging from eradicating disease to promoting educational equity, these experts are often intimidated by Bill’s knowledge base, which seems impossibly broad and deep. What if he spots a fatal flaw in my work? Will it be the end of my career here? A few years ago, leaders at the Gates Foundation reached out to see if I could help them build psychological safety. They were worried that the pressure to present airtight analyses was discouraging people from taking risks. They often stuck to tried-and-true strategies that would make incremental progress rather than daring to undertake bold experiments that might make a bigger dent in some of the world’s most vexing problems. The existing evidence on creating psychological safety gave us some starting points. I knew that changing the culture of an entire organization is daunting, while changing the culture of a team is more feasible. It starts with modeling the values we want to promote, identifying and praising others who exemplify them, and building a coalition of colleagues who are committed to making the change. The standard advice for managers on building psychological safety is to model openness and inclusiveness. Ask for feedback on how you can improve, and people will feel safe to take risks. To test whether that recommendation would work, I launched an experiment with a doctoral student, Constantinos Coutifaris. In multiple companies, we randomly assigned some managers to ask their teams for constructive criticism. Over the following week, their teams reported higher psychological safety, but as we anticipated, it didn’t last. Some managers who asked for feedback didn’t like what they heard and got defensive. Others found the feedback useless or felt helpless to act on it, which discouraged them from continuing to seek feedback and their teams from continuing to offer it. Another group of managers took a different approach, one that had less immediate impact in the first week but led to sustainable gains in psychological safety a full year later. Instead of asking them to seek feedback, we had randomly assigned those managers to share their past experiences with receiving feedback and their future development goals. We advised them to tell their teams about a time when they benefited from constructive criticism and to identify the areas that they were working to improve now. By admitting some of their imperfections out loud, managers demonstrated that they could take it—and made a public commitment to remain open to feedback. They normalized vulnerability, making their teams more comfortable opening up about their own struggles. Their employees gave more useful feedback because they knew where their managers were working to grow. That motivated managers to create practices to keep the door open: they started holding “ask me anything” coffee chats, opening weekly one-on-one meetings by asking for constructive criticism, and setting up monthly team sessions where everyone shared their development goals and progress. Creating psychological safety can’t be an isolated episode or a task to check off on a to-do list. When discussing their weaknesses, many of the managers in our experiment felt awkward and anxious at first. Many of their team members were surprised by that vulnerability and unsure of how to respond. Some were skeptical: they thought their managers might be fishing for compliments or cherry-picking comments that made them look good. It was only over time—as managers repeatedly demonstrated humility and curiosity—that the dynamic changed. At the Gates Foundation, I wanted to go a step further. Instea","date":"2022-09-03","objectID":"/think_again/:29:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"THE WORST THING ABOUT BEST PRACTICES In performance cultures, people often become attached to best practices. The risk is that once we’ve declared a routine the best, it becomes frozen in time. We preach about its virtues and stop questioning its vices, no longer curious about where it’s imperfect and where it could improve. Organizational learning should be an ongoing activity, but best practices imply it has reached an endpoint. We might be better off looking for better practices. At NASA, although teams routinely debriefed after both training simulations and significant operational events, what sometimes stood in the way of exploring better practices was a performance culture that held people accountable for outcomes. Every time they delayed a scheduled launch, they faced widespread public criticism and threats to funding. Each time they celebrated a flight that made it into orbit, they were encouraging their engineers to focus on the fact that the launch resulted in a success rather than on the faulty processes that could jeopardize future launches. That left NASA rewarding luck and repeating problematic practices, failing to rethink what qualified as an acceptable risk. It wasn’t for a lack of ability. After all, these were rocket scientists. As Ellen Ochoa observes, “When you are dealing with people’s lives hanging in the balance, you rely on following the procedures you already have. This can be the best approach in a time-critical situation, but it’s problematic if it prevents a thorough assessment in the aftermath.” Focusing on results might be good for short-term performance, but it can be an obstacle to long-term learning. Sure enough, social scientists find that when people are held accountable only for whether the outcome was a success or failure, they are more likely to continue with ill-fated courses of action. Exclusively praising and rewarding results is dangerous because it breeds overconfidence in poor strategies, incentivizing people to keep doing things the way they’ve always done them. It isn’t until a high-stakes decision goes horribly wrong that people pause to reexamine their practices. We shouldn’t have to wait until a space shuttle explodes or an astronaut nearly drowns to determine whether a decision was successful. Along with outcome accountability, we can create process accountability by evaluating how carefully different options are considered as people make decisions. A bad decision process is based on shallow thinking. A good process is grounded in deep thinking and rethinking, enabling people to form and express independent opinions. Research shows that when we have to explain the procedures behind our decisions in real time, we think more critically and process the possibilities more thoroughly. Process accountability might sound like the opposite of psychological safety, but they’re actually independent. Amy Edmondson finds that when psychological safety exists without accountability, people tend to stay within their comfort zone, and when there’s accountability but not safety, people tend to stay silent in an anxiety zone. When we combine the two, we create a learning zone. People feel free to experiment—and to poke holes in one another’s experiments in service of making them better. They become a challenge network. One of the most effective steps toward process accountability that I’ve seen is at Amazon, where important decisions aren’t made based on simple PowerPoint presentations. They’re informed by a six-page memo that lays out a problem, the different approaches that have been considered in the past, and how the proposed solutions serve the customer. At the start of the meeting, to avoid groupthink, everyone reads the memo silently. This isn’t practical in every situation, but it’s paramount when choices are both consequential and irreversible. Long before the results of the decision are known, the quality of the process can be evaluated based on the rigor and creativity of the author","date":"2022-09-03","objectID":"/think_again/:29:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"CHAPTER 11 ","date":"2022-09-03","objectID":"/think_again/:30:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Escaping Tunnel Vision ","date":"2022-09-03","objectID":"/think_again/:31:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"Reconsidering Our Best-Laid Career and Life Plans A malaise set in within a couple hours of my arriving. I thought getting a job might help. It turns out I have a lot of relatives in Hell, and, using connections, I became the assistant to a demon who pulls people’s teeth out. It wasn’t actually a job, more of an internship. But I was eager. And at first it was kind of interesting. After a while, though, you start asking yourself: Is this what I came to Hell for, to hand different kinds of pliers to a demon? —jack handey W**hat do you want to be when you grow up? As a kid, that was my least favorite question. I dreaded conversations with adults because they always asked it—and no matter how I replied, they never liked my answer. When I said I wanted to be a superhero, they laughed. My next goal was to make the NBA, but despite countless hours of shooting hoops on my driveway, I was cut from middle school basketball tryouts three years in a row. I was clearly aiming too high. In high school, I became obsessed with springboard diving and decided I wanted to become a diving coach. Adults scoffed at that plan: they told me I was aiming too low. In my first semester of college, I decided to major in psychology, but that didn’t open any doors—it just gave me a few to close. I knew I didn’t want to be a therapist (not patient enough) or a psychiatrist (too squeamish for med school). I was still aimless, and I envied people who had a clear career plan. From the time he was in kindergarten, my cousin Ryan knew exactly what he wanted to be when he grew up. Becoming a doctor wasn’t just the American dream—it was the family dream. Our great-grandparents emigrated from Russia and barely scraped by. Our grandmother was a secretary, and our grandfather worked in a factory, but it wasn’t enough to support five children, so he worked a second job delivering milk. Before his kids were teenagers, he had taught them to drive the milk truck so they could finish their 4:00 a.m. delivery cycle before the school day and workday started. When none of their children went on to med school (or milk delivery), my grandparents hoped our generation would bring the prestige of a Dr. Grant to the family. The first seven grandchildren didn’t become doctors. I was the eighth, and I worked multiple jobs to pay for college and to keep my options open. They were proud when I ended up getting my doctorate in psychology, but they still hoped for a real doctor. For the ninth grandchild, Ryan, who arrived four years after me, an M.D. was practically preordained. Ryan checked all the right boxes: along with being precocious, he had a strong work ethic. He set his sights on becoming a neurosurgeon. He was passionate about the potential to help people and ready to persist in the face of whatever obstacles would come into his path. When Ryan was looking at colleges, he came to visit me. As we started talking about majors, he expressed a flicker of doubt about the premed track and asked if he should study economics instead. There’s a term in psychology that captures Ryan’s personality: blirtatiousness. Yep, that’s an actual research concept, derived from the combination of blurting and flirting. When “blirters” meet people, their responses tend to be fast and effusive. They typically score high in extraversion and impulsiveness—and low in shyness and neuroticism. Ryan could push himself to study for long hours, but it drained him. Drawn to something more active and social, he toyed with the idea of squeezing in an economics major along with premed, but abandoned that idea when he got to college. Gotta stay on track. Ryan sailed through the premed curriculum and became a teaching assistant for undergrads while he was still an undergrad himself. When he showed up at exam review sessions and saw how stressed the students were, he refused to start covering the material until they stood up and danced. When he was accepted to an Ivy League medical school, he asked me if he should","date":"2022-09-03","objectID":"/think_again/:32:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"GOING INTO FORECLOSURE When we dedicate ourselves to a plan and it isn’t going as we hoped, our first instinct isn’t usually to rethink it. Instead, we tend to double down and sink more resources in the plan. This pattern is called escalation of commitment. Evidence shows that entrepreneurs persist with failing strategies when they should pivot, NBA general managers and coaches keep investing in new contracts and more playing time for draft busts, and politicians continue sending soldiers to wars that didn’t need to be fought in the first place. Sunk costs are a factor, but the most important causes appear to be psychological rather than economic. Escalation of commitment happens because we’re rationalizing creatures, constantly searching for self-justifications for our prior beliefs as a way to soothe our egos, shield our images, and validate our past decisions. Escalation of commitment is a major factor in preventable failures. Ironically, it can be fueled by one of the most celebrated engines of success: grit. Grit is the combination of passion and perseverance, and research shows that it can play an important role in motivating us to accomplish long-term goals. When it comes to rethinking, though, grit may have a dark side. Experiments show that gritty people are more likely to overplay their hands in roulette and more willing to stay the course in tasks at which they’re failing and success is impossible. Researchers have even suggested that gritty mountaineers are more likely to die on expeditions, because they’re determined to do whatever it takes to reach the summit. There’s a fine line between heroic persistence and foolish stubbornness. Sometimes the best kind of grit is gritting our teeth and turning around. Ryan escalated his commitment to medical training for sixteen years. If he had been less tenacious, he might have changed tracks sooner. Early on, he had fallen victim to what psychologists call identity foreclosure—when we settle prematurely on a sense of self without enough due diligence, and close our minds to alternative selves. In career choices, identity foreclosure often begins when adults ask kids: what do you want to be when you grow up? Pondering that question can foster a fixed mindset about work and self. “I think it’s one of the most useless questions an adult can ask a child,” Michelle Obama writes. “What do you want to be when you grow up? As if growing up is finite. As if at some point you become something and that’s the end.”* Some kids dream too small. They foreclose on following in family footsteps and never really consider alternatives. You probably know some people who faced the opposite problem. They dreamed too big, becoming attached to a lofty vision that wasn’t realistic. Sometimes we lack the talent to pursue our callings professionally, leaving them unanswered; other times there’s little hope that our passions can pay the bills. “You can be anything you wanna be?!” the comedian Chris Rock quipped. “Tell the kids the truth. . . . You can be anything you’re good at . . . as long as they’re hiring.” Even if kids get excited about a career path that does prove realistic, what they thought was their dream job can turn out to be a nightmare. Kids might be better off learning about careers as actions to take rather than as identities to claim. When they see work as what they do rather than who they are, they become more open to exploring different possibilities. Although children are often fascinated by science from a young age, over the course of elementary school, they tend to lose interest and confidence in their potential to be scientists. Recent studies show that it’s possible to maintain their enthusiasm by introducing them to science differently. When second and third graders learned about “doing science” rather than “being scientists,” they were more excited about pursuing science. Becoming a scientist might seem out of reach, but the act of experimenting is something we can all try ou","date":"2022-09-03","objectID":"/think_again/:32:1","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"TIME FOR A CHECKUP We foreclose on all kinds of life plans. Once you’ve committed to one, it becomes part of your identity, making it difficult to de-escalate. Declaring an English major because you love to read, only to discover that you don’t enjoy the process of writing. Deciding to start college during a pandemic, only to conclude later that you should have considered a gap year. Gotta stay on track. Ending a romantic relationship because you don’t want kids, only to realize years down the road that you might after all. Identity foreclosure can stop us from evolving. In a study of amateur musicians, those who had settled on music as a professional calling were more likely to ignore career advice from a trusted adviser over the course of the following seven years. They listened to their hearts and tuned out their mentors. In some ways, identity foreclosure is the opposite of an identity crisis: instead of accepting uncertainty about who we want to become, we develop compensatory conviction and plunge head over heels into a career path. I’ve noticed that the students who are the most certain about their career plans at twenty are often the ones with the deepest regrets by thirty. They haven’t done enough rethinking along the way.* Sometimes it’s because they’re thinking too much like politicians, eager to earn the approval of parents and peers. They become seduced by status, failing to see that no matter how much an accomplishment or affiliation impresses someone else, it’s still a poor choice if it depresses them. In other cases it’s because they’re stuck in preacher mode, and they’ve come to see a job as a sacred cause. And occasionally they pick careers in prosecutor mode, where they charge classmates with selling their souls to capitalism and hurl themselves into nonprofits in the hopes of saving the world. Sadly, they often know too little about the job—and too little about their evolving selves—to make a lifelong commitment. They get trapped in an overconfidence cycle, taking pride in pursuing a career identity and surrounding themselves with people who validate their conviction. By the time they discover it was the wrong fit, they feel it’s too late to think again. The stakes seem too high to walk away; the sacrifices of salary, status, skill, and time seem too great. For the record, I think it’s better to lose the past two years of progress than to waste the next twenty. In hindsight, identity foreclosure is a Band-Aid: it covers up an identity crisis, but fails to cure it. My advice to students is to take a cue from health-care professions. Just as they make appointments with the doctor and the dentist even when nothing is wrong, they should schedule checkups on their careers. I encourage them to put a reminder in their calendars to ask some key questions twice a year. When did you form the aspirations you’re currently pursuing, and how have you changed since then? Have you reached a learning plateau in your role or your workplace, and is it time to consider a pivot? Answering these career checkup questions is a way to periodically activate rethinking cycles. It helps students maintain humility about their ability to predict the future, contemplate doubts about their plans, and stay curious enough to discover new possibilities or reconsider previously discarded ones. I had one student, Marissa Shandell, who scored a coveted job at a prestigious consulting firm and planned on climbing up the ladder. She kept getting promoted early but found herself working around the clock. Instead of continuing to just grit and bear it, she and her husband had a career checkup conversation every six months, talking not just about the growth trajectory of their companies but also about the growth trajectory of their jobs. After being promoted to associate partner well ahead of schedule, Marissa realized she had reached a learning plateau (and a lifestyle plateau) and decided to pursue a doctorate in management.* Deciding to leave a c","date":"2022-09-03","objectID":"/think_again/:32:2","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"WHEN CHASING HAPPINESS CHASES IT AWAY When we think about how to plan our lives, there are few things that take priority over happiness. The kingdom of Bhutan has a Gross National Happiness index. In the United States, the pursuit of happiness is so prized that it’s one of the three unalienable rights in our Declaration of Independence. If we’re not careful, though, the pursuit of happiness can become a recipe for misery. Psychologists find that the more people value happiness, the less happy they often become with their lives. It’s true for people who naturally care about happiness and for people who are randomly assigned to reflect on why happiness matters. There’s even evidence that placing a great deal of importance on happiness is a risk factor for depression. Why? One possibility is that when we’re searching for happiness, we get too busy evaluating life to actually experience it. Instead of savoring our moments of joy, we ruminate about why our lives aren’t more joyful. A second likely culprit is that we spend too much time striving for peak happiness, overlooking the fact that happiness depends more on the frequency of positive emotions than their intensity. A third potential factor is that when we hunt for happiness, we overemphasize pleasure at the expense of purpose. This theory is consistent with data suggesting that meaning is healthier than happiness, and that people who look for purpose in their work are more successful in pursuing their passions—and less likely to quit their jobs—than those who look for joy. While enjoyment waxes and wanes, meaning tends to last. A fourth explanation is that Western conceptions of happiness as an individual state leave us feeling lonely. In more collectivistic Eastern cultures, that pattern is reversed: pursuing happiness predicts higher well-being, because people prioritize social engagement over independent activities. Last fall a student stopped by my office hours for some advice. She explained that when she chose Wharton, she had focused too much on getting into the best school and too little on finding the best fit. She wished she had picked a college with a more carefree culture and a stronger sense of community. Now that she was clear on her values, she was considering a transfer to a school that would make her happier. A few weeks later she told me that a moment in class had helped her rethink her plan. It wasn’t the research on happiness that we discussed, the values survey she took, or the decision-making activity we did. It was a comedy sketch I showed from Saturday Night Live. The scene stars Adam Sandler as a tour guide. In a mock commercial advertising his company’s Italian tours, he mentions that customer reviews sometimes express disappointment. He takes the opportunity to remind customers about what a vacation can and can’t do for them: There’s a lot a vacation can do: help you unwind, see some different-looking squirrels, but it cannot fix deeper issues, like how you behave in group settings. We can take you on a hike. We cannot turn you into someone who likes hiking. Remember, you’re still gonna be you on vacation. If you are sad where you are, and then you get on a plane to Italy, the you in Italy will be the same sad you from before, just in a new place. © Saturday Night Live/NBC When we pursue happiness, we often start by changing our surroundings. We expect to find bliss in a warmer climate or a friendlier dorm, but any joy that those choices bring about is typically temporary. In a series of studies, students who changed their environments by adjusting their living arrangements or course schedules quickly returned to their baseline levels of happiness. As Ernest Hemingway wrote, “You can’t get away from yourself by moving from one place to another.” Meanwhile, students who changed their actions by joining a new club, adjusting their study habits, or starting a new project experienced lasting gains in happiness. Our happiness often depends more on what we","date":"2022-09-03","objectID":"/think_again/:32:3","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"LIFE, LIBERTY, AND THE PURSUIT OF MEANING To be clear, I wouldn’t encourage anyone to stay in a role, relationship, or place they hated unless they had no other alternatives. Still, when it comes to careers, instead of searching for the job where we’ll be happiest, we might be better off pursuing the job where we expect to learn and contribute the most. Psychologists find that passions are often developed, not discovered. In a study of entrepreneurs, the more effort they put into their startups, the more their enthusiasm about their businesses climbed each week. Their passion grew as they gained momentum and mastery. Interest doesn’t always lead to effort and skill; sometimes it follows them. By investing in learning and problem solving, we can develop our passions—and build the skills necessary to do the work and lead the lives we find worthwhile. As we get older, we become more focused on searching for meaning—and we’re most likely to find it in actions that benefit others. My favorite test of meaningful work is to ask: if this job didn’t exist, how much worse off would people be? It’s near midlife that this question often begins to loom large. At around this time, in both work and life, we feel we have more to give (and less to lose), and we’re especially keen to share our knowledge and skills with the next generation. When my students talk about the evolution of self-esteem in their careers, the progression often goes something like this: Phase 1: I’m not important Phase 2: I’m important Phase 3: I want to contribute to something important I’ve noticed that the sooner they get to phase 3, the more impact they have and the more happiness they experience. It’s left me thinking about happiness less as a goal and more as a by-product of mastery and meaning. “Those only are happy,” philosopher John Stuart Mill wrote, “who have their minds fixed on some object other than their own happiness; on the happiness of others, on the improvement of mankind, even on some art or pursuit, followed not as a means, but as itself an ideal end. Aiming thus at something else, they find happiness by the way.” Careers, relationships, and communities are examples of what scientists call open systems—they’re constantly in flux because they’re not closed off from the environments around them. We know that open systems are governed by at least two key principles: there are always multiple paths to the same end (equifinality), and the same starting point can be a path to many different ends (multifinality). We should be careful to avoid getting too attached to a particular route or even a particular destination. There isn’t one definition of success or one track to happiness. My cousin Ryan finally wound up rethinking his career arc. Five years into his neurosurgery residency, he did his own version of a career checkup and decided to scratch his entrepreneurial itch. He cofounded a fast-growing, venture-backed startup called Nomad Health, which creates a marketplace to match clinicians with medical facilities. He also advised several medical device startups, filed medical device patents, and is now working on multiple startups to improve health care. Looking back, he still regrets that he foreclosed so early on an identity as a neurosurgeon and escalated his commitment to that career. At work and in life, the best we can do is plan for what we want to learn and contribute over the next year or two, and stay open to what might come next. To adapt an analogy from E. L. Doctorow, writing out a plan for your life “is like driving at night in the fog. You can only see as far as your headlights, but you can make the whole trip that way.” we don’t have to upend our entire paths to rethink some of our plans. Some people are perfectly content with their fields of work but dissatisfied with their current roles. Others may be too risk averse to make a geographic move for a job or a partner. And many don’t have the luxury of making a pivot: being economically dep","date":"2022-09-03","objectID":"/think_again/:32:4","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"I. INDIVIDUAL RETHINKING A. Develop the Habit of Thinking Again \\1. Think like a scientist. When you start forming an opinion, resist the temptation to preach, prosecute, or politick. Treat your emerging view as a hunch or a hypothesis and test it with data. Like the entrepreneurs who learned to approach their business strategies as experiments, you’ll maintain the agility to pivot. \\2. Define your identity in terms of values, not opinions. It’s easier to avoid getting stuck to your past beliefs if you don’t become attached to them as part of your present self-concept. See yourself as someone who values curiosity, learning, mental flexibility, and searching for knowledge. As you form opinions, keep a list of factors that would change your mind. \\3. Seek out information that goes against your views. You can fight confirmation bias, burst filter bubbles, and escape echo chambers by actively engaging with ideas that challenge your assumptions. An easy place to start is to follow people who make you think—even if you usually disagree with what they think. B. Calibrate Your Confidence \\4. Beware of getting stranded at the summit of Mount Stupid. Don’t confuse confidence with competence. The Dunning-Kruger effect is a good reminder that the better you think you are, the greater the risk that you’re overestimating yourself—and the greater the odds that you’ll stop improving. To prevent overconfidence in your knowledge, reflect on how well you can explain a given subject. \\5. Harness the benefits of doubt. When you find yourself doubting your ability, reframe the situation as an opportunity for growth. You can have confidence in your capacity to learn while questioning your current solution to a problem. Knowing what you don’t know is often the first step toward developing expertise. \\6. Embrace the joy of being wrong. When you find out you’ve made a mistake, take it as a sign that you’ve just discovered something new. Don’t be afraid to laugh at yourself. It helps you focus less on proving yourself—and more on improving yourself. C. Invite Others to Question Your Thinking \\7. Learn something new from each person you meet. Everyone knows more than you about something. Ask people what they’ve been rethinking lately, or start a conversation about times you’ve changed your mind in the past year. \\8. Build a challenge network, not just a support network. It’s helpful to have cheerleaders encouraging you, but you also need critics to challenge you. Who are your most thoughtful critics? Once you’ve identified them, invite them to question your thinking. To make sure they know you’re open to dissenting views, tell them why you respect their pushback—and where they usually add the most value. \\9. Don’t shy away from constructive conflict. Disagreements don’t have to be disagreeable. Although relationship conflict is usually counterproductive, task conflict can help you think again. Try framing disagreement as a debate: people are more likely to approach it intellectually and less likely to take it personally. ","date":"2022-09-03","objectID":"/think_again/:33:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"II. INTERPERSONAL RETHINKING A. Ask Better Questions \\10. Practice the art of persuasive listening. When we’re trying to open other people’s minds, we can frequently accomplish more by listening than by talking. How can you show an interest in helping people crystallize their own views and uncover their own reasons for change? A good way to start is to increase your question-to-statement ratio. \\11. Question how rather than why. When people describe why they hold extreme views, they often intensify their commitment and double down. When they try to explain how they would make their views a reality, they often realize the limits of their understanding and start to temper some of their opinions. \\12. Ask “What evidence would change your mind?” You can’t bully someone into agreeing with you. It’s often more effective to inquire about what would open their minds, and then see if you can convince them on their own terms. \\13. Ask how people originally formed an opinion. Many of our opinions, like our stereotypes, are arbitrary; we’ve developed them without rigorous data or deep reflection. To help people reevaluate, prompt them to consider how they’d believe different things if they’d been born at a different time or in a different place. B. Approach Disagreements as Dances, Not Battles \\14. Acknowledge common ground. A debate is like a dance, not a war. Admitting points of convergence doesn’t make you weaker—it shows that you’re willing to negotiate about what’s true, and it motivates the other side to consider your point of view. \\15. Remember that less is often more. If you pile on too many different reasons to support your case, it can make your audiences defensive—and cause them to reject your entire argument based on its least compelling points. Instead of diluting your argument, lead with a few of your strongest points. \\16. Reinforce freedom of choice. Sometimes people resist not because they’re dismissing the argument but because they’re rejecting the feeling of their behavior being controlled. It helps to respect their autonomy by reminding them that it’s up to them to choose what they believe. \\17. Have a conversation about the conversation. If emotions are running hot, try redirecting the discussion to the process. Like the expert negotiators who comment on their feelings and test their understanding of the other side’s feelings, you can sometimes make progress by expressing your disappointment or frustration and asking people if they share it. ","date":"2022-09-03","objectID":"/think_again/:34:0","tags":["think"],"title":"Think Again","uri":"/think_again/"},{"categories":["think"],"content":"III. COLLECTIVE RETHINKING A. Have More Nuanced Conversations \\18. Complexify contentious topics. There are more than two sides to every story. Instead of treating polarizing issues like two sides of a coin, look at them through the many lenses of a prism. Seeing the shades of gray can make us more open. \\19. Don’t shy away from caveats and contingencies. Acknowledging competing claims and conflicting results doesn’t sacrifice interest or credibility. It’s an effective way to engage audiences while encouraging them to stay curious. \\20. Expand your emotional range. You don’t have to eliminate frustration or even indignation to have a productive conversation. You just need to mix in a broader set of emotions along with them—you might try showing some curiosity or even admitting confusion or ambivalence. B. Teach Kids to Think Again \\21. Have a weekly myth-busting discussion at dinner. It’s easier to debunk false beliefs at an early age, and it’s a great way to teach kids to become comfortable with rethinking. Pick a different topic each week—one day it might be dinosaurs, the next it could be outer space—and rotate responsibility around the family for bringing a myth for discussion. \\22. Invite kids to do multiple drafts and seek feedback from others. Creating different versions of a drawing or a story can encourage kids to learn the value of revising their ideas. Getting input from others can also help them to continue evolving their standards. They might learn to embrace confusion—and to stop expecting perfection on the first try. \\23. Stop asking kids what they want to be when they grow up. They don’t have to define themselves in terms of a career. A single identity can close the door to alternatives. Instead of trying to narrow their options, help them broaden their possibilities. They don’t have to be one thing—they can do many things. C. Create Learning Organizations \\24. Abandon best practices. Best practices suggest that the ideal routines are already in place. If we want people to keep rethinking the way they work, we might be better off adopting process accountability and continually striving for better practices. \\25. Establish psychological safety. In learning cultures, people feel confident that they can question and challenge the status quo without being punished. Psychological safety often starts with leaders role-modeling humility. \\26. Keep a rethinking scorecard. Don’t evaluate decisions based only on the results; track how thoroughly different options are considered in the process. A bad process with a good outcome is luck. A good process with a bad outcome might be a smart experiment. D. Stay Open to Rethinking Your Future \\27. Throw out the ten-year plan. What interested you last year might bore you this year—and what confused you yesterday might become exciting tomorrow. Passions are developed, not just discovered. Planning just one step ahead can keep you open to rethinking. \\28. Rethink your actions, not just your surroundings. Chasing happiness can chase it away. Trading one set of circumstances for another isn’t always enough. Joy can wax and wane, but meaning is more likely to last. Building a sense of purpose often starts with taking actions to enhance your learning or your contribution to others. \\29. Schedule a life checkup. It’s easy to get caught in escalation of commitment to an unfulfilling path. Just as you schedule health checkups with your doctor, it’s worth having a life checkup on your calendar once or twice a year. It’s a way to assess how much you’re learning, how your beliefs and goals are evolving, and whether your next steps warrant some rethinking. \\30. Make time to think again. When I looked at my calendar, I noticed that it was mostly full of doing. I set a goal of spending an hour a day thinking and learning. Now I’ve decided to go further: I’m scheduling a weekly time for rethinking and unlearning. I reach out to my challenge network and ask what ideas and opinions they think I s","date":"2022-09-03","objectID":"/think_again/:35:0","tags":["think"],"title":"Think Again","uri":"/think_again/"}]